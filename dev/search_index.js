var documenterSearchIndex = {"docs":
[{"location":"S1_getting_started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Before official release, we recommend the following practice to download and use PDMO.jl. ","category":"page"},{"location":"S1_getting_started/#Installation","page":"Getting Started","title":"Installation","text":"","category":"section"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Download the package and cd into the project folder.","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"cd PDMO","category":"page"},{"location":"S1_getting_started/#HSL-Setup-(Optional)","page":"Getting Started","title":"HSL Setup (Optional)","text":"","category":"section"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"PDMO.jl relies on Ipopt.jl to solve certain ADMM subproblems. Linear solvers can significantly affect the performance of Ipopt. For enhanced performance, you can optionally use linear solvers from HSL. If HSL is available, linear solver MA27 will be used for Ipopt by default.","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Default setup (HSL not required): No additional setup needed. PDMO.jl will use Ipopt's default linear solver.","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Enhanced performance with HSL: ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Obtain HSL library from https://www.hsl.rl.ac.uk/\nSet up your HSL_jll directory with the following structure:\nHSL_jll/\n└── override/\n    └── lib/\n        └── {SYSTEM_ARCHITECTURE}/\n            └── libhsl.{so|dylib}\nExample architectures: x86_64-linux-gnu-libgfortran5, aarch64-apple-darwin-libgfortran5\nEdit warmup.jl and update the HSL path:\n# Uncomment and modify this line:\nHSL_PATH = \"/path/to/your/HSL_jll\"","category":"page"},{"location":"S1_getting_started/#Project-Setup","page":"Getting Started","title":"Project Setup","text":"","category":"section"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Run the setup script:","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"julia warmup.jl","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"This one-time step will:","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Set up all required dependencies\nConfigure HSL if available\nReport HSL detection status","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"After successful setup, PDMO.jl is ready for use:","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"using PDMO","category":"page"},{"location":"S1_getting_started/#Quick-Start","page":"Getting Started","title":"Quick Start","text":"","category":"section"},{"location":"S1_getting_started/#Dual-Square-Root-LASSO","page":"Getting Started","title":"Dual Square Root LASSO","text":"","category":"section"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"We use the Dual Square Root LASSO as a beginning example: ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"beginaligned\n    min_x zquad  langle b xrangle \n    mathrmst quad  Ax - z = 0 \n     x_2 leq 1 z_infty leq lambda\nendaligned","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"where (A b lambda) are given problem data of proper dimensions. ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"To begin with, load PDMO.jl and other necessary packages.","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"using PDMO\nusing LinearAlgebra\nusing SparseArrays\nusing Random ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Next generate or load your own problem data. We use synthetic data here. ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"numberRows = 10 \nnumberColumns = 20 \nA = sparse(randn(numberRows, numberColumns))\nb = randn(numberColumns)\nlambda = 1.0","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Then we can generate a MultiblockProblem for the Dual Square Root LASSO problem.","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"mbp = MultiblockProblem()\n\n# add x block\nblock_x = BlockVariable() \nblock_x.f = AffineFunction(b, 0.0)    # f_1(x) = <b, x>\nblock_x.g = IndicatorBallL2(1.0)      # g_1(x) = indicator of L2 ball \nblock_x.val = zeros(numberColumns)    # initial value\nxID = addBlockVariable!(mbp, block_x) # add x block to mbp; an ID is assigned\n\n# add z block \nblock_z = BlockVariable()                              \nblock_z.g = IndicatorBox(-lambda * ones(numberRows), # f_2(z) = Zero() by default\n    ones(numberRows) * lambda)                       # g_2(x) = indicator of box\nblock_z.val = zeros(numberRows)                      # initial value\nzID = addBlockVariable!(mbp, block_z)                # add z block to mbp; an ID is assigned\n\n# add constraint: Ax-z=0\nconstr = BlockConstraint() \naddBlockMappingToConstraint!(constr, xID, LinearMappingMatrix(A))      # specify the mapping of x\naddBlockMappingToConstraint!(constr, zID, LinearMappingIdentity(-1.0)) # specify the mapping of z \nconstr.rhs = zeros(numberRows)                                         # specify RHS\naddBlockConstraint!(mbp, constr)                                       # add constraint to mbp","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Next we can run different variants of ADMM: ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run ADMM \nparam = ADMMParam() \nparam.solver = OriginalADMMSubproblemSolver()\nparam.adapter = RBAdapter(testRatio=10.0, adapterRatio=2.0)\nparam.accelerator = AndersonAccelerator()\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run Doubly Linearized ADMM\nparam = ADMMParam() \nparam.solver = DoublyLinearizedSolver() \nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run Adaptive Linearized ADMM\nparam = ADMMParam() \nparam.solver = AdaptiveLinearizedSolver()\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"or different adaptive primal-dual methods: ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run AdaPDM \nparamAdaPDM = AdaPDMParam(mbp)\nresult = runAdaPDM(mbp, paramAdaPDM)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run AdaPDMPlus \nparamAdaPDMPlus = AdaPDMPlusParam(mbp)\nresult = runAdaPDM(mbp, paramAdaPDMPlus)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run Malitsky-Pock \nparamMalitskyPock = MalitskyPockParam(mbp)\nresult = runAdaPDM(mbp, paramMalitskyPock)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"# run Condat-Vu \nparamCondatVu = CondatVuParam(mbp)\nresult = runAdaPDM(mbp, paramCondatVu)","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"Upon termination of the selected algorithm, one can look for primal solution and iteration information through result.solution and result.iterationInfo, respectively. ","category":"page"},{"location":"S1_getting_started/#User-Defined-Smooth-and-Proximable-Functions","page":"Getting Started","title":"User Defined Smooth and Proximable Functions","text":"","category":"section"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"In addition to a set of built-in functions whose gradient or proximal oracles have been implemented, PDMO.jl supports user defined smooth and proximable functions. Consider the function ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"    F(x) = x_1 + x_2 + x_3^4 x = x_1 x_2 x_3^top in mathbbR^3","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"which can be expressed as the sum of a smooth f and a proximable g: ","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"    f(x) = x_1 + x_3^4 quad g(x) = x_2","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"In PDMO.jl, this block can be constructed as follows:","category":"page"},{"location":"S1_getting_started/","page":"Getting Started","title":"Getting Started","text":"block = BlockVariable()\nblock.f = UserDefinedSmoothFunction(\n    x -> x[1] + x[3]^4,                  # f\n    x -> [1.0, 0.0, 4*x[3]^3])           # ∇f\nblock.g = UserDefinedProximalFunction(\n    x -> abs(x[2]),                      # g\n    (x, gamma) -> [                      # prox_{gamma g} \n        x[1], \n        sign(x[2]) * max(abs(x[2]) - gamma, 0.0),\n        x[3]])\nblock.val = zeros(3)                     # initial value","category":"page"},{"location":"S3_examples/DistributedOPF/#Distributed-Optimal-Power-Flow-(DC-OPF)","page":"Distributed OPF","title":"Distributed Optimal Power Flow (DC OPF)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"This example demonstrates how to solve DC Optimal Power Flow problems in a distributed manner using ADMM with bipartization algorithms.","category":"page"},{"location":"S3_examples/DistributedOPF/#Problem-Background","page":"Distributed OPF","title":"Problem Background","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/#DC-Optimal-Power-Flow","page":"Distributed OPF","title":"DC Optimal Power Flow","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"DC Optimal Power Flow (DC OPF) is a fundamental optimization problem in electric power systems. The goal is to find the most cost-effective way to dispatch power generators while satisfying all network constraints under the DC power flow approximation.","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Consider a power network G(N E) where N is the set of buses and E is the set of transmission lines. Let G_i be the set of generators at bus i, and G = cup_iin NG_i be all generators. The DC OPF problem is formulated as:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"beginaligned\nmin quad  sum_g in G c_g(P_g) \ntextst quad  sum_gin G_iP_g - P^D_i = sum_j (ij)in E f_ij quad forall i in N \n f_ij = B_ij(theta_i - theta_j) quad forall (ij) in E \n underlineP_g leq P_g leq overlineP_g quad forall g in G \n underlinef_ij leq f_ij leq overlinef_ij quad forall (ij) in E\nendaligned","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Decision Variables:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Real power generated by generator g: P_g\nVoltage angle at bus i: theta_i\nPower flow on transmission line (ij): f_ij","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Constraints:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Power balance: Net power injection equals outflow at each bus\nPower flow equations: Flow proportional to angle difference (DC approximation)\nGeneration limits: Generator capacity bounds\nTransmission limits: Thermal flow limits on lines","category":"page"},{"location":"S3_examples/DistributedOPF/#Distributed-Reformulation","page":"Distributed OPF","title":"Distributed Reformulation","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"The power network is partitioned into P zones Z_1 ldots Z_P, each controlled by a separate agent. For each zone p in P:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Zone buses: Z_p contains buses controlled by agent p\nBoundary buses: textNB_p contains neighboring buses from other zones\nExtended zone: overlineZ_p = Z_p cup textNB_p includes all buses agent p needs to consider\nTie lines: Lines connecting buses in different zones, denoted by textTL","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"In real-world power systems, there's often a need for distributed solutions:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Power grids span multiple regions controlled by different operators\nCritical system information cannot be shared between regions\nLarge-scale problems require distributed computation for efficiency","category":"page"},{"location":"S3_examples/DistributedOPF/#Distributed-DC-OPF-Formulation","page":"Distributed OPF","title":"Distributed DC OPF Formulation","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Each agent p maintains local copies of variables for its extended zone:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"x_p = left(P_g^p_gin G_i iin Z_p theta^p_i_i in overlineZ_p f^p_ij_(ij)in Ecap(Z_p times overlineZ_p) right)","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Local Constraint Set: X_p = x_p  textlocal power balance generation limits flow equations and limits","category":"page"},{"location":"S3_examples/DistributedOPF/#Distributed-DC-OPF-Formulation-2","page":"Distributed OPF","title":"Distributed DC OPF Formulation","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"The original centralized problem is reformulated as:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"beginaligned\nmin_x_p_pin P quad  sum_p=1^P left(sum_gin G_i iin Z_p c_g(P_g^p)right) \ntextst quad  theta^z(i)_i = theta^z(j)_i quad forall (ij)in textTL \n theta^z(i)_j = theta^z(j)_j quad forall (ij)in textTL \n f^z(i)_ij= f^z(j)_ij quad forall (ij)in textTL \n x_p in X_p quad forall p in P\nendaligned","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Where z(i) denotes the zone containing bus i.","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Key Features:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Separable objective: Generation costs are distributed across zones. They are usually quaradtic or linear with respect to real power generations, and hence are differentiable. \nConsensus constraints: Ensure consistency for tie line variables. These constraints will be relaxed through the augmented Lagrangian function. \nLocal constraints: Each zone maintains its own feasible region. We assume the proximal oracle of X_p, i.e., projection onto X_p can be computed. This requres minimizing a quadratic function over linear constraints defined by X_p. ","category":"page"},{"location":"S3_examples/DistributedOPF/#Zone-Partitioning","page":"Distributed OPF","title":"Zone Partitioning","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"The distributed formulation above is suitable for ADMM only if the zone connectivity graph is bipartite. When zones are connected in non-bipartite patterns (containing odd cycles), subproblems corresponding to connected zones are coupled together and hence ADMM are not applicable. ","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Core Idea: PDMO.jl will automatically transform the non-bipartite zone graph into a bipartite form through the following three-step process:","category":"page"},{"location":"S3_examples/DistributedOPF/#1.-Detect","page":"Distributed OPF","title":"1. Detect","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Bipartite structure detection: Automatically detect if the zone connectivity graph is bipartite or contains odd cycles\nGraph assessment: Determine if transformation is needed (e.g., if there are only two zones, the graph is already bipartite)","category":"page"},{"location":"S3_examples/DistributedOPF/#2.-Transform-using-User-Selected-Algorithm","page":"Distributed OPF","title":"2. Transform using User-Selected Algorithm","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Algorithm selection: Apply the user-specified bipartization algorithm to transform the graph into a bipartite structure\nEdge subdivision: Break odd cycles by strategically subdividing problematic edges","category":"page"},{"location":"S3_examples/DistributedOPF/#3.-Prepare-Necessary-Data-Structures","page":"Distributed OPF","title":"3. Prepare Necessary Data Structures","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Introduce auxiliary variables: Create new consensus variables at subdivision points to maintain problem equivalence\nAdd new consensus constraints: Establish additional equality constraints linking original and auxiliary variables\nUpdate coupling structure: Ensure all inter-zone couplings follow the bipartite pattern (each constraint couples exactly one \"left\" variable with one \"right\" variable)","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"After this automatic transformation procedure, the OPF problem achieves the desired structure:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Bipartite connectivity: All zones can be assigned to \"left\" or \"right\" partitions\nSimple couplings: Each consensus constraint involves exactly two zones from different partitions\nADMM-ready: Direct application of ADMM with theoretical convergence guarantees","category":"page"},{"location":"S3_examples/DistributedOPF/#Experimental-Setup","page":"Distributed OPF","title":"Experimental Setup","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/#Test-Cases","page":"Distributed OPF","title":"Test Cases","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"We evaluate the above distributed approach on standard IEEE test systems. These data files are available in Matpower. ","category":"page"},{"location":"S3_examples/DistributedOPF/#Partitioning-Strategy","page":"Distributed OPF","title":"Partitioning Strategy","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"We use METIS.jl to divide each network into 3-10 zones, where each zone represents a separate control area.  As the partitions given by METIS.jl are in general not bipartitie, we further compare two bipartization algorithms: ","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"MILP Bipartization: Use mixed-integer programming to minimize cetrain metric related to the worst case iteration complexity. \nBFS Bipartization: Heuristic using breadth-first search to break odd cycles. ","category":"page"},{"location":"S3_examples/DistributedOPF/#ADMM-Parameters","page":"Distributed OPF","title":"ADMM Parameters","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"param = ADMMParam()\nparam.solver = AdaptiveLinearizedSolver(gamma=1.0, r=1e5)\nparam.maxIter = 500000\nparam.timeLimit = 7200      # time limit in seconds\nparam.presTolL2 = Inf \nparam.dresTolL2 = Inf \nparam.presTolLInf = 1e-3    # report optimal if max primal/dual\nparam.dresTolLInf = 1e-3    # residuals are less than 1e-3","category":"page"},{"location":"S3_examples/DistributedOPF/#Results","page":"Distributed OPF","title":"Results","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"The experimental results demonstrate the effectiveness of the bipartization approach across different IEEE test systems. Below we present detailed performance comparisons between MILP and BFS bipartization algorithms for each test case.","category":"page"},{"location":"S3_examples/DistributedOPF/#Case-30-(30-bus-system)","page":"Distributed OPF","title":"Case 30 (30-bus system)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Performance Summary:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Partitions MILP Iters MILP Time (s) MILP Abs Diff BFS Iters BFS Time (s) BFS Abs Diff\n3 696 4.75 6.00e-04 696 2.77 6.00e-04\n4 1462 6.05 2.39e-02 4421 17.81 1.88e-02\n5 565 2.24 1.00e-02 804 3.11 1.60e-03\n6 680 2.97 1.61e-02 680 2.65 1.61e-02\n7 720 3.32 7.10e-03 612 2.65 8.20e-03\n8 733 3.34 4.50e-03 792 3.61 1.70e-03\n9 2598 11.96 1.13e-02 1560 6.60 1.36e-02\n10 2586 13.28 1.36e-02 1614 6.97 1.00e-04\nAverage 1255 5.99 1.09e-02 1397 5.77 7.60e-03","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Overall Statistics:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"MILP: Average 1255.0 iterations, 5.99s, 8/8 convergence\nBFS: Average 1397.4 iterations, 5.77s, 8/8 convergence","category":"page"},{"location":"S3_examples/DistributedOPF/#Case-57-(57-bus-system)","page":"Distributed OPF","title":"Case 57 (57-bus system)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Performance Summary:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Partitions MILP Iters MILP Time (s) MILP Abs Diff BFS Iters BFS Time (s) BFS Abs Diff\n3 4717 21.83 0.00e+00 4722 19.29 0.00e+00\n4 3369 14.07 2.20e-01 5530 21.78 6.00e-02\n5 7685 31.38 0.00e+00 9168 38.21 1.80e-01\n6 12651 51.16 4.00e-02 9907 40.31 1.80e-01\n7 9119 36.91 7.30e-01 11176 45.76 2.70e-01\n8 7012 30.59 2.00e-01 11661 54.55 1.00e-01\n9 12450 72.65 2.80e-01 20922 141.91 3.70e-01\n10 30712 197.54 9.00e-02 43959 282.54 2.00e-02\nAverage 10964 57.02 1.95e-01 14631 80.54 1.48e-01","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Overall Statistics:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"MILP: Average 10964.4 iterations, 57.02s, 8/8 convergence\nBFS: Average 14630.6 iterations, 80.54s, 8/8 convergence","category":"page"},{"location":"S3_examples/DistributedOPF/#Case-89pegase-(89-bus-system)","page":"Distributed OPF","title":"Case 89pegase (89-bus system)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Performance Summary:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Partitions MILP Iters MILP Time (s) MILP Abs Diff BFS Iters BFS Time (s) BFS Abs Diff\n3 100740 818.72 0.00e+00 58182 493.29 0.00e+00\n4 70619 573.48 0.00e+00 70619 556.25 0.00e+00\n5 152987 1169.31 1.00e-02 127198 797.80 1.00e-02\n6 347983 2166.73 1.00e-02 212998 1302.99 1.00e-02\n7 172778 1107.11 0.00e+00 118400 719.54 0.00e+00\n8 399074 2945.31 0.00e+00 500000* 3776.84 0.00e+00\n9 424753 3306.33 0.00e+00 416630 2763.47 0.00e+00\n10 500000* 3508.14 0.00e+00 500000* 3893.15 0.00e+00\nAverage 271117 1949.39 2.50e-03 250503 1787.92 2.50e-03","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"*Hit iteration limit","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Overall Statistics:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"MILP: Average 271116.8 iterations, 1949.39s, 7/8 convergence\nBFS: Average 250503.4 iterations, 1787.92s, 6/8 convergence","category":"page"},{"location":"S3_examples/DistributedOPF/#Case-118-(118-bus-system)","page":"Distributed OPF","title":"Case 118 (118-bus system)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Partitions MILP Iters MILP Time (s) MILP Abs Diff BFS Iters BFS Time (s) BFS Abs Diff\n3 500000* 3328.25 6.00e-02 500000* 3134.82 6.00e-02\n4 196674 1192.41 0.00e+00 219267 1357.12 2.00e-02\n5 157265 913.78 1.00e-02 421100 2538.47 5.00e-02\n6 469894 2861.42 1.00e-02 310285 1878.80 1.00e-02\n7 500000* 3134.15 7.00e-02 500000* 3916.00 1.00e-01\n8 327146 2056.68 0.00e+00 273241 2532.66 1.00e-02\n9 500000* 3287.07 4.00e-02 500000* 3298.54 2.60e-01\n10 247418 1609.12 0.00e+00 500000* 4097.89 3.00e-02\nAverage 362300 2297.86 2.38e-02 402987 2844.29 6.75e-02","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"*Hit iteration limit","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Overall Statistics:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"MILP: Average 362299.6 iterations, 2297.86s, 5/8 convergence\nBFS: Average 402986.6 iterations, 2844.29s, 4/8 convergence","category":"page"},{"location":"S3_examples/DistributedOPF/#Case-300-(300-bus-system)","page":"Distributed OPF","title":"Case 300 (300-bus system)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Partitions MILP Iters MILP Time (s) MILP Abs Diff BFS Iters BFS Time (s) BFS Abs Diff\n3 500000* 6595.10 2.00e-02 500000* 5745.13 3.00e-02\n4 44125 451.56 4.00e-02 46336 470.23 1.00e-02\n5 63456 613.71 1.00e-02 62758 605.65 1.00e-02\n6 141267 1262.08 1.00e-02 256760 2301.45 1.00e-02\n7 88318 755.26 1.00e-02 86520 736.64 2.00e-02\n8 320560 2671.08 1.00e-02 441353 4476.19 2.00e-02\n9 78130 674.80 1.00e-02 75884 636.14 3.00e-02\n10 333189 2867.36 0.00e+00 317086 2589.16 1.00e-02\nAverage 196131 1986.37 1.38e-02 223337 2195.08 1.75e-02","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"*Hit iteration limit","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Overall Statistics:","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"MILP: Average 196130.6 iterations, 1986.37s, 7/8 convergence \nBFS: Average 223337.1 iterations, 2195.08s, 7/8 convergence","category":"page"},{"location":"S3_examples/DistributedOPF/#Case-1888rte-(1888-bus-system)","page":"Distributed OPF","title":"Case 1888rte (1888-bus system)","text":"","category":"section"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Partitions MILP Iters MILP Time (s) MILP Abs Diff BFS Iters BFS Time (s) BFS Abs Diff\n3 101368 5511.77 0.00e+00 101368 5610.75 0.00e+00\n4 148390 6423.14 0.00e+00 135895 5857.55 0.00e+00\n5 196675 6945.33 0.00e+00 193456 7200.01* 1.00e-02\n6 228659 6742.48 0.00e+00 228659 6839.82 0.00e+00\n7 243140 7200.00* 0.00e+00 237310 7070.78 0.00e+00\n8 247383 7029.14 0.00e+00 212039 5732.35 0.00e+00\n9 231385 6112.67 0.00e+00 226505 5970.93 0.00e+00\n10 164693 4072.68 0.00e+00 216148 7200.01* 0.00e+00\nAverage 195212 6254.65 0.00e+00 193923 6435.27 1.25e-03","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"*Hit time limit","category":"page"},{"location":"S3_examples/DistributedOPF/","page":"Distributed OPF","title":"Distributed OPF","text":"Note: The experiments presented here are primarily intended to demonstrate the correctness of bipartization algorithms and illustrate how different reformulations affect ADMM convergence behavior. The distributed approach is not currently designed to compete with centralized solvers in terms of computational efficiency. We will focus on performance optimization and scalability improvements in future development.","category":"page"},{"location":"S4_api/admm/#ADMM","page":"ADMM","title":"ADMM","text":"","category":"section"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"This page documents the Alternating Direction Method of Multipliers (ADMM) algorithm components in PDMO.jl.","category":"page"},{"location":"S4_api/admm/#Overview","page":"ADMM","title":"Overview","text":"","category":"section"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"PDMO.jl provides a comprehensive ADMM implementation with the following key components:","category":"page"},{"location":"S4_api/admm/#Parameters-and-Iteration-Information","page":"ADMM","title":"Parameters and Iteration Information","text":"","category":"section"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"ADMMParam - Main parameter configuration for ADMM algorithms\nADMMIterationInfo - Stores iteration-specific information and statistics","category":"page"},{"location":"S4_api/admm/#Subproblem-Solvers","page":"ADMM","title":"Subproblem Solvers","text":"","category":"section"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"Various implementations for solving ADMM subproblems:","category":"page"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"AbstractADMMSubproblemSolver - Base abstract type for all ADMM subproblem solvers\nOriginalADMMSubproblemSolver - Standard ADMM subproblem solver\nSpecializedOriginalADMMSubproblemSolver - Optimized versions for specific problem types\nLinearSolver - For linear subproblems\nJuMPSolver - Interface to JuMP optimization models\nProximalMappingSolver - Uses proximal mappings\nDoublyLinearizedSolver - Linearized approximation approach\nAdaptiveLinearizedSolver - Adaptive linearization strategy","category":"page"},{"location":"S4_api/admm/#Adapters","page":"ADMM","title":"Adapters","text":"","category":"section"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"Penalty parameter adaptation strategies:","category":"page"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"AbstractADMMAdapter - Base type for adaptation strategies\nRBAdapter - Residual balancing adaptation\nSRAAdapter - Spectral radius adaptation","category":"page"},{"location":"S4_api/admm/#Accelerators","page":"ADMM","title":"Accelerators","text":"","category":"section"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"Acceleration techniques for improving convergence:","category":"page"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"AbstractADMMAccelerator - Base type for acceleration methods\nAndersonAccelerator - Anderson acceleration scheme\nAutoHalpernAccelerator - Automatic Halpern acceleration","category":"page"},{"location":"S4_api/admm/","page":"ADMM","title":"ADMM","text":"Note: Detailed API documentation with function signatures and examples will be added in a future release.","category":"page"},{"location":"S4_api/functions/#Functions","page":"Functions","title":"Functions","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"This page documents the function components available in PDMO.jl for modeling optimization problems.","category":"page"},{"location":"S4_api/functions/#Overview","page":"Functions","title":"Overview","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"PDMO.jl provides a comprehensive library of functions commonly used in convex optimization, including both smooth and non-smooth functions.","category":"page"},{"location":"S4_api/functions/#Abstract-Base-Types","page":"Functions","title":"Abstract Base Types","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"AbstractFunction - Base abstract type for all functions\nAbstractFunctionUtil - Utilities for function operations","category":"page"},{"location":"S4_api/functions/#Smooth-Functions","page":"Functions","title":"Smooth Functions","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"Differentiable functions with gradient information:","category":"page"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"AffineFunction - Linear and affine functions\nQuadraticFunction - Quadratic functions with matrix representation\nComponentwiseExponentialFunction - Element-wise exponential functions\nUserDefinedSmoothFunction - User-defined smooth functions with custom gradients","category":"page"},{"location":"S4_api/functions/#Non-smooth-Functions","page":"Functions","title":"Non-smooth Functions","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"Non-differentiable functions with proximal operators:","category":"page"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"ElementwiseL1Norm - Element-wise L1 norm (absolute value)\nMatrixNuclearNorm - Nuclear norm for matrices\nWeightedMatrixL1Norm - Weighted L1 norm for matrices\nUserDefinedProximalFunction - User-defined functions with custom proximal operators","category":"page"},{"location":"S4_api/functions/#Indicator-Functions","page":"Functions","title":"Indicator Functions","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"Functions that enforce constraints by being zero on feasible sets and infinite elsewhere:","category":"page"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"IndicatorBox - Box constraints (upper and lower bounds)\nIndicatorBallL2 - L2 ball constraints\nIndicatorHyperplane - Hyperplane constraints\nIndicatorLinearSubspace - Linear subspace constraints\nIndicatorNonnegativeOrthant - Non-negativity constraints\nIndicatorPSD - Positive semidefinite matrix constraints\nIndicatorSOC - Second-order cone constraints\nIndicatorRotatedSOC - Rotated second-order cone constraints\nIndicatorSumOfNVariables - Sum equality constraints\nUserDefinedIndicatorFunction - User-defined indicator functions","category":"page"},{"location":"S4_api/functions/#Utility-Functions","page":"Functions","title":"Utility Functions","text":"","category":"section"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"Special purpose and wrapper functions:","category":"page"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"Zero - Zero function (always returns 0)\nFrobeniusNormSquare - Squared Frobenius norm for matrices\nWrapperScalarInputFunction - Wrapper for scalar input functions\nWrapperScalingTranslationFunction - Scaling and translation wrapper","category":"page"},{"location":"S4_api/functions/","page":"Functions","title":"Functions","text":"Note: Detailed API documentation with function signatures and examples will be added in a future release. ","category":"page"},{"location":"S2_algorithms/ADMM/#Alternating-Direction-Method-of-Multipliers-(ADMM)","page":"ADMM","title":"Alternating Direction Method of Multipliers (ADMM)","text":"","category":"section"},{"location":"S2_algorithms/ADMM/#Introduction-and-Solution-Process-Overview","page":"ADMM","title":"Introduction and Solution Process Overview","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The Alternating Direction Method of Multipliers (ADMM) is a powerful optimization algorithm that decomposes complex problems into simpler subproblems. The original ADMM solves convex optimization problems in the standard two-block form:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"beginaligned\nmin_xz quad  f(x) + h(y) \ntextst quad  Ax + By = c\nendaligned","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The algorithm alternates between three updates:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"beginalign\n   x^k+1 =  argmin_x  f(x) + langle u^k Ax + By^k - crangle + fracrho2Ax + By^k - c^2  notag \n   y^k+1 =  argmin_y h(y) + langle u^k Ax^k+1 + By - crangle + fracrho2Ax^k+1 + By - c^2 notag \n   u^k+1 =  u^k + rho(Ax^k+1 + By^k+1 - c) notag \nendalign","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"where rho  0 is the penalty parameter and u is the dual variable. When f and A (resp. h and B) admit certain  block-angular structures, the update of x^k+1 (resp. y^k+1) can be further parallelized. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"In practice, many optimization problems naturally arise in multiblock form with more than two variable blocks:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"beginaligned\nmin_x_1ldotsx_n quad  sum_j=1^n f_j(x_j) + g_j(x_j) \ntextst quad  sum_j in 1cdotsn A_ij x_j = b_i   j in 1cdots m\nendaligned","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"where A_ij is non-zero if and only constraint i involes block x_j.  PDMO.jl implements a comprehensive ADMM framework designed to solve multiblock optimization problems through an automated three-stage process:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"User Input: A user-defined MultiblockProblem together with a set of algorithmic options, i.e., ADMM subproblem solver, adapter, and accelerator. \nBipartization: Automatic reformulation using graph-based algorithms to convert the input problem into bipartite form, on which standard ADMM and variants","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"can be readily applied. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"ADMM Execution: The selected ADMM variant solves the reformulated problem with usder-specified algorithmic options. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"We provide more details regarding these three stages in the following sections. ","category":"page"},{"location":"S2_algorithms/ADMM/#MultiblockProblem:-A-Unified-Structure-for-Block-structued-Problems","page":"ADMM","title":"MultiblockProblem: A Unified Structure for Block-structued Problems","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"A MultiblockProblem is a container for multiblock optimization problems, maintaining collections of block variables and block constraints. The structure serves as the primary input to PDMO.jl.","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"mutable struct MultiblockProblem\n    blocks::Vector{BlockVariable}\n    constraints::Vector{BlockConstraint}\nend","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"blocks: A vector containing all block variables in the problem\nconstraints: A vector containing all block constraints connecting the variables","category":"page"},{"location":"S2_algorithms/ADMM/#BlockVariable","page":"ADMM","title":"BlockVariable","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"A BlockVariable represents an individual optimization variable block with its associated objective functions:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"mutable struct BlockVariable \n    id::BlockID                    # Unique identifier (Int64 or String)\n    f::AbstractFunction            # Smooth function component\n    g::AbstractFunction            # Nonsmooth/proximal function component  \n    val::NumericVariable           # Current variable value\nend","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Components:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"id: Unique identifier for the block (can be integer or string)\nf: Smooth function component f_i (e.g., quadratic, affine, exponential functions)\ng: Nonsmooth function component g_i handled via proximal operators (e.g., indicator functions, norms)\nval: Current value of the variable (scalar or vector)","category":"page"},{"location":"S2_algorithms/ADMM/#BlockConstraint","page":"ADMM","title":"BlockConstraint","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"A BlockConstraint represents equality constraints connecting multiple block variables:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"mutable struct BlockConstraint \n    id::BlockID                                    # Unique identifier\n    involvedBlocks::Vector{BlockID}                # Block IDs participating in constraint\n    mappings::Dict{BlockID, AbstractMapping}       # Linear mappings for each block\n    rhs::NumericVariable                           # Right-hand side value\nend","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Components:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"id: Unique identifier for the constraint\ninvolvedBlocks: Vector of block IDs that participate in this constraint\nmappings: Dictionary mapping each block ID to its linear transformation\nrhs: Right-hand side of the equality constraint","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Each constraint enforces the relationship:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"sum_i in textinvolvedBlocks (textmappingsi)(x_i) = textrhs ","category":"page"},{"location":"S2_algorithms/ADMM/#Graph-based-Bipartization","page":"ADMM","title":"Graph-based Bipartization","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Many optimization problems naturally arise in multiblock form where constraints involve more than two variable blocks.  Since a direct application of ADMM to multiblick problem may fail to converge, PDMO.jl automatically converts these  problems into bipartite form, i.e., a formulation where there are only two blocks, while each block consists of one or more sub-blocks. We briefly outline the procedures used by PDMO.jl to achieve this goal. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"To begin with, PDMO.jl will map a MultiblockProblem instance onto a graph with the following procedures:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"For each BlockVariable, introduce a new node in the graph. \nFor each BlockConstraint involving exactly 2 blocks, add an edge between the two corresponding nodes. \nFor each BlockConstraint involving more than 2 blocks, introduce a new node for this constraint, and connect this node with every node representing an involved block.  ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"In this way, a graph representation of a MultiblockProblem instance is constructed. As an illustrative example, consider a multiblock problem:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"beginaligned\n    min_x_1 x_2 x_3 quad  f_1(x_1) + f_2(x_2) + f_3(x_3)\n    mathrmstquad   A_1x_1 + A_2x_2 +A_3x_3 = a  \n     B_1x_1 + B_2x_2 = b\n     C_2x_2 + C_3x_3 = c\nendaligned","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"whose corresponding graph is show as the following: ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"<div style=\"text-align: center; margin: 20px 0;\">\n  <svg width=\"400\" height=\"300\" viewBox=\"0 0 400 300\">\n    <!-- Variable and constraint nodes -->\n    <circle cx=\"100\" cy=\"80\" r=\"25\" fill=\"#ADD8E6\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"100\" y=\"85\" text-anchor=\"middle\" font-size=\"16\">x₁</text>\n    \n    <circle cx=\"100\" cy=\"220\" r=\"25\" fill=\"#ADD8E6\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"100\" y=\"225\" text-anchor=\"middle\" font-size=\"16\">x₃</text>\n    \n    <circle cx=\"300\" cy=\"80\" r=\"25\" fill=\"#ADD8E6\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"300\" y=\"85\" text-anchor=\"middle\" font-size=\"16\">x₂</text>\n    \n    <circle cx=\"300\" cy=\"220\" r=\"25\" fill=\"#FFA500\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"300\" y=\"225\" text-anchor=\"middle\" font-size=\"16\">C</text>\n    <text x=\"300\" y=\"275\" text-anchor=\"middle\" font-size=\"12\">A₁x₁ + A₂x₂ + A₃x₃ = a</text>\n    \n    <!-- Edges -->\n    <line x1=\"125\" y1=\"80\" x2=\"275\" y2=\"80\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"125\" y1=\"220\" x2=\"275\" y2=\"80\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"275\" y1=\"220\" x2=\"125\" y2=\"80\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"300\" y1=\"195\" x2=\"300\" y2=\"105\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"275\" y1=\"220\" x2=\"125\" y2=\"220\" stroke=\"#000\" stroke-width=\"2\"/>\n  </svg>\n</div>","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Edges (x_1 x_2) and (x_2 x_3) represent constraints B_1x_1 + B_2x_2 = b and C_2x_2 + C_3x_3 = c, respectively.  Node C corresponds to a new BlockVariable that has a proximal-friendly component g: the indicator function of the set ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Y = (y_1 y_2 y_3) y_1 + y_2 + y_3 = 0","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The edge between C and x_i represent the artifical constraint A_ix_i - y_i = 0 for i in 123. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"PDMO.jl includes algorithms to convert a graph into bipartite form using a key operation called edge subdivision, which replaces an edge by a path of length 2. More specificly, for an edge e with endpoints denoted by x_i and x_j, introduce a new node, delete the original e, and connect the new node with with n_i and n_j respectively. Continuing with the previous example, we can remove the edge between C and x_2, introduc a new node in green, and this new node with C and x_2 respectively. The resulting graph becomes bipartite. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"<div style=\"text-align: center; margin: 20px 0;\">\n  <svg width=\"500\" height=\"350\" viewBox=\"0 0 500 350\">\n    <!-- Left Partition -->\n    <text x=\"80\" y=\"320\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"bold\">Left Partition</text>\n    <circle cx=\"80\" cy=\"60\" r=\"25\" fill=\"#ADD8E6\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"80\" y=\"65\" text-anchor=\"middle\" font-size=\"16\">x₁</text>\n    <circle cx=\"80\" cy=\"150\" r=\"25\" fill=\"#ADD8E6\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"80\" y=\"155\" text-anchor=\"middle\" font-size=\"16\">x₃</text>\n    <circle cx=\"80\" cy=\"240\" r=\"25\" fill=\"#90EE90\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"80\" y=\"245\" text-anchor=\"middle\" font-size=\"12\">C-x₂</text>\n    \n    <!-- Right Partition -->\n    <text x=\"420\" y=\"320\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"bold\">Right Partition</text>\n    <circle cx=\"420\" cy=\"60\" r=\"25\" fill=\"#ADD8E6\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"420\" y=\"65\" text-anchor=\"middle\" font-size=\"16\">x₂</text>\n    <circle cx=\"420\" cy=\"150\" r=\"25\" fill=\"#FFA500\" stroke=\"#000\" stroke-width=\"2\"/>\n    <text x=\"420\" y=\"155\" text-anchor=\"middle\" font-size=\"16\">C</text>\n    \n    <!-- Edges -->\n    <line x1=\"105\" y1=\"65\" x2=\"395\" y2=\"65\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"105\" y1=\"65\" x2=\"395\" y2=\"155\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"105\" y1=\"155\" x2=\"395\" y2=\"65\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"105\" y1=\"155\" x2=\"395\" y2=\"155\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"105\" y1=\"245\" x2=\"395\" y2=\"65\" stroke=\"#000\" stroke-width=\"2\"/>\n    <line x1=\"105\" y1=\"245\" x2=\"395\" y2=\"155\" stroke=\"#000\" stroke-width=\"2\"/>\n    \n    <!-- Partition boundary -->\n    <line x1=\"250\" y1=\"40\" x2=\"250\" y2=\"290\" stroke=\"#888\" stroke-width=\"3\" stroke-dasharray=\"10,5\"/>\n  </svg>\n</div>","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The newly introduce node (in green) also introduce a new BlockVariable with a proximal-friendly function g: the indicator function of the set of a free variable z, which has the same shape as A_2x_2 and y_2. The previous edge between x_2 and C, representing A_2x_2 - y_2 = 0, is replaced by two new edges: the one between x_2 and the new node represents A_2x_2-z = 0, and the other one between C and the new node represents y_2-z=0. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The edge subdivision operation essentially introduces auxiliary variables to break complicated couplings between variables and constraints. The goal is to construct an equivalent reformulation of the original problem, where all BlockVariables can be assigned either to the left or to the right, and each constraint couples exactly one BlockVariable on the left, and another on the right. Currently PDMO.jl supports the following bipartization algorithms based on edge splitting. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Algorithm Procedure\nMILP_BIPARTIZATION (1) Formulate as MILP with binary variables (2) Add constraints for valid bipartition (3) Minimize operator norms and graph complexity\nBFS_BIPARTIZATION (1) Traverse graph level-by-level using BFS (2) Assign nodes to alternating partitions (3) Split edges when conflicts detected\nDFS_BIPARTIZATION (1) Traverse graph depth-first using DFS (2) Assign nodes to alternating partitions (3) Split edges when conflicts detected\nSPANNING_TREE_BIPARTIZATION (1) Construct spanning tree (2) 2-color the spanning tree (3) Split back edges only if endpoints have same partition","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The specific bipartization algorithm can be selected as a keyword argument to the function runBipartiteADMM via ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"# suppose the following arguments have been constructed: \n#  1. mbp: a MultiblockProblem of interest\n#  2. param: user-specified ADMM parameters\nresult = runBipartiteADMM(mbp, param;\n    bipartizationAlgorithm = BFS_BIPARTIZATION\n    # or bipartizationAlgorithm = MILP_BIPARTIZATION\n    # or bipartizationAlgorithm = DFS_BIPARTIZATION\n    # or bipartizationAlgorithm = SPANNING_TREE_BIPARTIZATION\n)","category":"page"},{"location":"S2_algorithms/ADMM/#ADMM-Algorithmic-Components","page":"ADMM","title":"ADMM Algorithmic Components","text":"","category":"section"},{"location":"S2_algorithms/ADMM/#Subproblem-Solvers","page":"ADMM","title":"Subproblem Solvers","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"PDMO.jl implements multiple subproblem solvers corresponding to different ADMM variants. ","category":"page"},{"location":"S2_algorithms/ADMM/#Original-ADMM-Subproblem-Solver-(OriginalADMMSubproblemSolver)","page":"ADMM","title":"Original ADMM Subproblem Solver (OriginalADMMSubproblemSolver)","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The OriginalADMMSubproblemSolver solves the ADMM subproblems exactly, i.e., without any linearization techniques, ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"  x^k+1 = argmin_x f(x) + g(x) + langle u^k Ax + By^k - crangle + fracrho2Ax+ By^k-c^2","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"using specialized methods based on automatic problem structure detection.","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam()\nparam.solver = OriginalADMMSubproblemSolver()","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"To handle diverse problem characteristics and computational requirements, OriginalADMMSubproblemSolver might further invoke different specialized solvers for different nodal subproblems: ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"LinearSolver: A linear solver based on Cholesky or LDL' decomposition for subproblems equivalent to linear systems\nProximalMappingSolver: A solver for subproblems reducible to proximal mappings of corresponding g\nJuMPSolver: A general-purpose solver using JuMP optimization modeling and Ipopt. Note: supports for function modeling in JuMP are limited at the moment and under active development. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"When a specialized solver cannot be determined for a nodal problem, PDMO.jl will switch to the doubly linearized solver. ","category":"page"},{"location":"S2_algorithms/ADMM/#Doubly-Linearized-Solver-(DoublyLinearizedSolver)","page":"ADMM","title":"Doubly Linearized Solver (DoublyLinearizedSolver)","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The DoublyLinearizedSolver implements the Doubly Linearized ADMM for updating primal variables: ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"beginaligned\nx^k+1 =  mathrmprox_alpha g(x^k - alpha (nabla f(x^k) + A^top u^k + rho A^top(Ax^k+By^k-c))) \nendaligned","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"where alpha 0 is a proximal coefficient. Since linearization is applied to the original smooth function f as well as the augmented Lagrangian terms, this update only invokes gradient oracles of f and proximal oracles of g. See Chapter 8 of Ryu and Yin [1] for details. The DoublyLinearizedSolver can be initialized as follows. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam()\nparam.solver = DoublyLinearizedSolver()","category":"page"},{"location":"S2_algorithms/ADMM/#Adaptive-Linearized-Solver-(AdaptiveLinearizedSolver)","page":"ADMM","title":"Adaptive Linearized Solver (AdaptiveLinearizedSolver)","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The AdaptiveLinearizedSolver is a newly developed method that combines linearization with adaptive step size mechanisms for robust performance. Details of this method will be released soon. The AdaptiveLinearizedSolver can be initialized as follows.","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam()\nparam.solver = AdaptiveLinearizedSolver()","category":"page"},{"location":"S2_algorithms/ADMM/#Penalty-Adapter","page":"ADMM","title":"Penalty Adapter","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Penalty parameter adapters dynamically adjust the penalty parameter rho during ADMM iterations to improve convergence. PDMO.jl currently implements two penalty adapters: ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Residual Balancing Adapter (RBAdapter): Balances primal and dual residuals by adjusting rho based on their ratio to improve convergence stability.","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam() \nparam.adapter = RBAdapter(\n  testRatio = 10.0,   # Threshold ratio for primal and dual residuals\n  adapterRatio = 2.0) # Factor by which to multiply/divide ρ ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Spectral Radius Approximation Adapter (SRAAdapter): Uses spectral analysis of iteration history to adaptively update rho based on convergence rate estimation. See [2] for more details. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam() \nparam.adapter = SRAAdapter(\n  T=5,                   # History length\n  increasingFactor=2.0,  # Factor by which to multiply ρ\n  decreasingFactor=2.0)  # Factor by which to divide ρ","category":"page"},{"location":"S2_algorithms/ADMM/#Accelerator","page":"ADMM","title":"Accelerator","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Acceleration schemes enhance ADMM convergence by exploiting iteration history. PDMO.jl currently implements two acceleraton schemes: ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Anderson Accelerator (AndersonAccelerator): See [3] for more details. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam()\nparam.accelerator = AndersonAccelerator() ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Auto Halpern Accelerator (AutoHalpernAccelerator): A newly developed restarted Halpern acceleration scheme for ADMM. Details will be released soon. ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam()\nparam.accelerator = AutoHalpernAccelerator()","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Note: Although the modular design enables flexible combination of algorithmic components, not all combinations of solver, adapter, and accelerator are equally effective. Some may result in slower convergence or numerical issues. Please experiment thoughtfully and validate performance for your specific use case.","category":"page"},{"location":"S2_algorithms/ADMM/#Termination-Criteria","page":"ADMM","title":"Termination Criteria","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"PDMO.jl implements comprehensive termination criteria with multiple levels:","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Level 1: Basic Termination","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Optimality: Primal and dual residuals satisfy tolerances\nIteration limit: Maximum iterations reached\nTime limit: Wall-clock time limit exceeded\nNumerical errors: NaN or Inf values detected","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Level 2: Advanced Problem Classification (Under active development) ","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Infeasibility detection: Problem has no feasible solution\nUnboundedness detection: Objective function is unbounded below\nIll-posed problem detection: Problem is weakly infeasible, or has non-zero duality gap","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"The system automatically classifies problems into categories (Case A-F) based on convergence behavior patterns, helping users understand why ADMM may not converge on certain problem instances.","category":"page"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"param = ADMMParam()\nparam.enablePathologyCheck = true  # Enable advanced problem classification\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S2_algorithms/ADMM/#References","page":"ADMM","title":"References","text":"","category":"section"},{"location":"S2_algorithms/ADMM/","page":"ADMM","title":"ADMM","text":"Ryu, E. K., & Yin, W. (2022). Large-scale convex optimization: algorithms & analyses via monotone operators. Cambridge University Press.\nMcCann, M. T., & Wohlberg, B. (2024). Robust and Simple ADMM Penalty Parameter Selection. IEEE Open Journal of Signal Processing, 5, 402-420.\nPollock, S., & Rebholz, L. G. (2023). Filtering for Anderson acceleration. SIAM Journal on Scientific Computing, 45(4), A1571-A1590.","category":"page"},{"location":"S4_api/mappings/#Mappings","page":"Mappings","title":"Mappings","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"This page documents the linear mapping components in PDMO.jl for representing linear operators between variable blocks.","category":"page"},{"location":"S4_api/mappings/#Overview","page":"Mappings","title":"Overview","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"PDMO.jl provides efficient implementations of linear mappings that connect different variable blocks in multiblock optimization problems.","category":"page"},{"location":"S4_api/mappings/#Abstract-Base-Type","page":"Mappings","title":"Abstract Base Type","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"AbstractMapping - Base abstract type for all linear mappings","category":"page"},{"location":"S4_api/mappings/#Linear-Mapping-Types","page":"Mappings","title":"Linear Mapping Types","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Core linear mapping implementations:","category":"page"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"LinearMappingMatrix - Dense matrix representation of linear operators\nLinearMappingIdentity - Identity mapping for efficiency\nLinearMappingExtraction - Extraction/selection mappings for subsets of variables","category":"page"},{"location":"S4_api/mappings/#Mapping-Operations","page":"Mappings","title":"Mapping Operations","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Standard operations supported by all mappings:","category":"page"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Forward application: A * x (matrix-vector multiplication)\nAdjoint application: A' * y (adjoint/transpose operation)\nComposition: combining multiple mappings\nScaling: scalar multiplication of mappings","category":"page"},{"location":"S4_api/mappings/#Efficient-Implementations","page":"Mappings","title":"Efficient Implementations","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Specialized implementations for common cases:","category":"page"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Sparse matrix support for large-scale problems\nIdentity mappings with O(1) storage\nBlock-diagonal structures\nExtraction operators for variable selection","category":"page"},{"location":"S4_api/mappings/#Integration-with-Block-Structure","page":"Mappings","title":"Integration with Block Structure","text":"","category":"section"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"How mappings work within the multiblock framework:","category":"page"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Connecting variable blocks to constraint blocks\nAutomatic adjoint computation\nMemory-efficient storage and computation\nSupport for both dense and sparse representations","category":"page"},{"location":"S4_api/mappings/","page":"Mappings","title":"Mappings","text":"Note: Detailed API documentation with function signatures and examples will be added in a future release.","category":"page"},{"location":"S4_api/pdm/#AdaPDM","page":"AdaPDM","title":"AdaPDM","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"This page documents the Adaptive Primal-Dual Method (AdaPDM) algorithm components in PDMO.jl.","category":"page"},{"location":"S4_api/pdm/#Overview","page":"AdaPDM","title":"Overview","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"AdaPDM is a family of adaptive primal-dual algorithms that automatically adjust step sizes for optimal convergence. PDMO.jl provides several variants and supporting utilities.","category":"page"},{"location":"S4_api/pdm/#Parameters-and-Iteration-Information","page":"AdaPDM","title":"Parameters and Iteration Information","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"Algorithm parameter configuration:","category":"page"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"AbstractAdaPDMParam - Base abstract type for all AdaPDM parameters\nAdaPDMParam - Standard AdaPDM algorithm parameters\nAdaPDMPlusParam - AdaPDM+ variant with enhanced features\nMalitskyPockParam - Parameters for Malitsky-Pock algorithm\nCondatVuParam - Parameters for Condat-Vu algorithm\nAdaPDMIterationInfo - Iteration-specific information and statistics\nAdaPDMTerminationStatus - Status indicators for algorithm termination","category":"page"},{"location":"S4_api/pdm/#Core-Algorithm-Functions","page":"AdaPDM","title":"Core Algorithm Functions","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"Main algorithmic components:","category":"page"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"computeNormEstimate - Estimates operator norms for step size computation\ngetAdaPDMName - Returns the name of the current AdaPDM variant","category":"page"},{"location":"S4_api/pdm/#Update-Functions","page":"AdaPDM","title":"Update Functions","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"Algorithm-specific update procedures:","category":"page"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"updateDualSolution! - Updates the dual variable in each iteration\nupdatePrimalSolution! - Updates the primal variable in each iteration\nsetupInitialPrimalDualStepSize! - Initializes step sizes for primal and dual variables","category":"page"},{"location":"S4_api/pdm/#Iteration-Utilities","page":"AdaPDM","title":"Iteration Utilities","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"Supporting functions for iteration management:","category":"page"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"computeAdaPDMDualResiduals! - Computes dual residuals for convergence checking\ncomputeAdaPDMPrimalResiduals! - Computes primal residuals for convergence checking\ncomputePDMResidualsAndObjective! - Computes both residuals and objective value\ncomputePartialObjective! - Computes partial objective function values\ncomputeLipschitzAndCocoercivityEstimate - Estimates Lipschitz and cocoercivity constants\nprepareProximalCenterForConjugateProximalOracle! - Prepares centers for conjugate proximal operations\nprepareProximalCenterForPrimalUpdate! - Prepares centers for primal updates","category":"page"},{"location":"S4_api/pdm/#Termination-Management","page":"AdaPDM","title":"Termination Management","text":"","category":"section"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"Convergence and termination checking:","category":"page"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"AdaPDMTerminationCriteria - Defines termination criteria\ncheckTerminationCriteria - Main termination checking function\ncheckOptimalTermination - Checks for optimal solution conditions\ncheckIterationLimit - Checks iteration count limits\ncheckTimeLimit - Checks time-based termination\ncheckNumericalError - Detects numerical instabilities\ncheckUnboundedness - Detects unbounded problems\ngetTerminationStatus - Returns current termination status","category":"page"},{"location":"S4_api/pdm/","page":"AdaPDM","title":"AdaPDM","text":"Note: Detailed API documentation with function signatures and examples will be added in a future release.","category":"page"},{"location":"S3_examples/LeastL1Norm/#Least-L1-Norm-Benchmark-Results","page":"Least L1 Norm","title":"Least L1 Norm Benchmark Results","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/#Problem-Formulation","page":"Least L1 Norm","title":"Problem Formulation","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"The Least L1 Norm problem aims to minimize the L1 norm of the residual:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"min_x Ax - b_1","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"where:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"A is an m × n matrix \nb is an m-dimensional vector\nx is the n-dimensional optimization variable","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"For ADMM decomposition, this is reformulated as a two-block problem:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"beginaligned\nmin_x z quad  z_1 \nmathrmst quad  Ax - z = b\nendaligned","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"This reformulation enables efficient distributed solving using bipartite ADMM.","category":"page"},{"location":"S3_examples/LeastL1Norm/#Solver-References","page":"Least L1 Norm","title":"Solver References","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/#[JuMP](https://github.com/jump-dev/JuMP.jl)-Solvers","page":"Least L1 Norm","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"SCS: Splitting Conic Solver\nCOSMO.jl: Conic Operator Splitting Method  \nClarabel.jl: Interior Point Conic Solver\nMadNLP.jl: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/LeastL1Norm/#Implementation-Examples","page":"Least L1 Norm","title":"Implementation Examples","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/#JuMP-Implementation","page":"Least L1 Norm","title":"JuMP Implementation","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Here's how to implement the Least L1 Norm problem using JuMP with the epigraph formulation:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"function solveLeastL1NormByJuMP(A::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, solver_optimizer=SCS.Optimizer; warmup=false)\n\n    m, n = size(A)\n\n    # Create JuMP model with specified optimizer\n    model = Model(solver_optimizer)\n    set_silent(model)\n    \n    # Define optimization variable\n    @variable(model, x[1:n])\n    \n    # Define auxiliary variables for L1 norm ||Ax - b||_1\n    # We use the epigraph formulation: ||Ax - b||_1 <= sum(t), -t <= Ax - b <= t\n    @variable(model, t[1:m] >= 0)\n    \n    # Define objective: sum(t) which represents ||Ax - b||_1\n    @objective(model, Min, sum(t))\n    \n    # Define constraints for L1 norm: -t <= Ax - b <= t (split into two constraints)\n    residual = A * x - b\n    @constraint(model, residual .<= t)\n    @constraint(model, residual .>= -t)\n    \n    # Solve the problem and get solver time directly from JuMP\n    optimize!(model)\n    solver_time = solve_time(model)\n    \n    status = termination_status(model)\n    optimal_value = objective_value(model)\n    optimal_x = value.(x)\n    \n    return optimal_value, solver_time\nend","category":"page"},{"location":"S3_examples/LeastL1Norm/#Multiblock-Problem-Implementation","page":"Least L1 Norm","title":"Multiblock Problem Implementation","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Here's how to formulate the same problem as a multiblock problem for ADMM using the PDMO framework:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"function generateLeastL1Norm(A::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64})\n    mbp = MultiblockProblem() \n\n    numberRows numberCols = size(A)\n\n    # x block \n    block_x = BlockVariable()  \n    block_x.val = randn(numberCols)\n    xID = addBlockVariable!(mbp, block_x)\n\n    # z block \n    block_z = BlockVariable()\n    block_z.g = ElementwiseL1Norm()\n    block_z.val = A * mbp.blocks[1].val - b \n    zID = addBlockVariable!(mbp, block_z)\n\n    # constraint: Ax-z = b\n    constr = BlockConstraint() \n    addBlockMappingToConstraint!(constr, xID, LinearMappingMatrix(A))\n    addBlockMappingToConstraint!(constr, zID, LinearMappingIdentity(-1.0))\n    constr.rhs = b\n    addBlockConstraint!(mbp, constr)\n\n    return mbp\n\nend","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"After generating the multiblock problem, you can solve it using various ADMM configurations:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"# ADMM with RB Adapter\nparam = ADMMParam(\n    adapter = RBAdapter(testRatio=10.0, adapterRatio=2.0),\n    presTolL2 = Inf,\n    dresTolL2 = Inf,\n    presTolLInf = 1e-4,\n    dresTolLInf = 1e-4\n)\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S3_examples/LeastL1Norm/#Benchmark-Methodology","page":"Least L1 Norm","title":"Benchmark Methodology","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"The benchmark compares multiple solution approaches:","category":"page"},{"location":"S3_examples/LeastL1Norm/#JuMP-Solvers","page":"Least L1 Norm","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"SCS: Splitting Conic Solver\nCOSMO: Conic Operator Splitting Method\nClarabel: Interior Point Conic Solver  \nMadNLP: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/LeastL1Norm/#ADMM-Variants","page":"Least L1 Norm","title":"ADMM Variants","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Original ADMM: Standard ADMM with different configurations\nAccelerated ADMM: With Anderson and Auto-Halpern accelerators\nAdaptive ADMM: With RB and SRA adapters\nLinearized ADMM: Adaptive and doubly linearized variants","category":"page"},{"location":"S3_examples/LeastL1Norm/#Problem-Scales","page":"Least L1 Norm","title":"Problem Scales","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Small: 500 × 250 (500 constraints, 250 variables)\nMedium: 1000 × 500 (1000 constraints, 500 variables)\nLarge: 2000 × 1000 (2000 constraints, 1000 variables)","category":"page"},{"location":"S3_examples/LeastL1Norm/#Performance-Results","page":"Least L1 Norm","title":"Performance Results","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/#Small-Scale-(500-250)","page":"Least L1 Norm","title":"Small Scale (500 × 250)","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Solver Time (s) Status Speedup vs Slowest\nMadNLP 9.83 LOCALLY_SOLVED 1.00x (reference)\nSCS 6.89 OPTIMAL 1.43x\nCOSMO 2.34 ITERATION_LIMIT 4.20x\nIpopt 1.39 LOCALLY_SOLVED 7.08x\nClarabel 0.63 OPTIMAL 15.51x","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + Halpern only 1.77 5.54x 6,350 OPTIMAL\nOriginal ADMM + RB + Halpern 2.10 4.69x 8,552 OPTIMAL\nOriginal ADMM + Anderson only 2.46 3.99x 3,186 OPTIMAL\nOriginal ADMM + RB Adapter 4.07 2.41x 16,697 OPTIMAL\nOriginal ADMM (baseline) 6.66 1.48x 21,774 OPTIMAL","category":"page"},{"location":"S3_examples/LeastL1Norm/#Medium-Scale-(1000-500)","page":"Least L1 Norm","title":"Medium Scale (1000 × 500)","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Solver Time (s) Status Speedup vs Slowest\nSCS 36.94 OPTIMAL 1.00x (reference)\nMadNLP 13.28 LOCALLY_SOLVED 2.78x\nCOSMO 12.08 ITERATION_LIMIT 3.06x\nIpopt 11.59 LOCALLY_SOLVED 3.19x\nClarabel 5.20 OPTIMAL 7.11x","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + RB + Halpern 7.70 4.80x 8,143 OPTIMAL\nOriginal ADMM + Halpern only 11.79 3.13x 12,412 OPTIMAL\nOriginal ADMM + Anderson only 14.38 2.57x 4,864 OPTIMAL\nOriginal ADMM + RB Adapter 22.03 1.68x 23,514 OPTIMAL\nOriginal ADMM (baseline) 24.91 1.48x 26,234 OPTIMAL","category":"page"},{"location":"S3_examples/LeastL1Norm/#Large-Scale-(2000-1000)","page":"Least L1 Norm","title":"Large Scale (2000 × 1000)","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Solver Time (s) Status Speedup vs Slowest\nSCS 367.16 OPTIMAL 1.00x (reference)\nIpopt 188.52 LOCALLY_SOLVED 1.95x\nMadNLP 164.25 LOCALLY_SOLVED 2.24x\nCOSMO 113.49 ITERATION_LIMIT 3.24x\nClarabel 56.42 OPTIMAL 6.51x","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + RB Adapter 54.91 6.69x 9,742 OPTIMAL\nOriginal ADMM + RB + Halpern 63.96 5.74x 11,493 OPTIMAL\nOriginal ADMM + Anderson only 159.97 2.30x 8,127 OPTIMAL\nOriginal ADMM (baseline) 282.29 1.30x 51,226 OPTIMAL\nOriginal ADMM + Halpern only 283.16 1.30x 46,426 OPTIMAL","category":"page"},{"location":"S3_examples/LeastL1Norm/#Multi-Scale-Performance-Summary","page":"Least L1 Norm","title":"Multi-Scale Performance Summary","text":"","category":"section"},{"location":"S3_examples/LeastL1Norm/","page":"Least L1 Norm","title":"Least L1 Norm","text":"Scale JuMP Reference Best ADMM Method ADMM Time Speedup Status\nSmall (500×250) MadNLP: 9.83s Original ADMM + Halpern only 1.77s 5.54x OPTIMAL\nMedium (1000×500) SCS: 36.94s Original ADMM + RB + Halpern 7.70s 4.80x OPTIMAL\nLarge (2000×1000) SCS: 367.16s Original ADMM + RB Adapter 54.91s 6.69x OPTIMAL","category":"page"},{"location":"S4_api/main/#Main-API","page":"Main","title":"Main API","text":"","category":"section"},{"location":"S4_api/main/","page":"Main","title":"Main","text":"This page documents the main API interface for PDMO.jl.","category":"page"},{"location":"S4_api/main/#Core-Functions","page":"Main","title":"Core Functions","text":"","category":"section"},{"location":"S4_api/main/","page":"Main","title":"Main","text":"The main entry points for using PDMO.jl:","category":"page"},{"location":"S4_api/main/","page":"Main","title":"Main","text":"solve! - Primary function for solving optimization problems using PDMO algorithms\nAdditional solver interfaces and utilities","category":"page"},{"location":"S4_api/main/","page":"Main","title":"Main","text":"Note: Detailed API documentation with function signatures and examples will be added in a future release.","category":"page"},{"location":"S3_examples/DualSVM/#Dual-SVM-Benchmark-Results","page":"Dual SVM","title":"Dual SVM Benchmark Results","text":"","category":"section"},{"location":"S3_examples/DualSVM/#Problem-Formulation","page":"Dual SVM","title":"Problem Formulation","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"The Dual Support Vector Machine problem is a quadratic programming problem with linear constraints:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"beginaligned\nmin_x quad  frac12langle Qx x rangle - langle e x rangle \nmathrmst quad  langle b x rangle = 0 \n 0 leq x_i leq C quad forall i\nendaligned","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"where:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Q is an n × n positive definite matrix (kernel matrix)\nb is an n-dimensional vector (class labels)\ne is the vector of all ones\nx is the n-dimensional optimization variable (dual variables)\nC is the regularization parameter","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"For ADMM decomposition, this is reformulated as a two-block problem:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"beginaligned\nmin_x z quad  frac12langle Qx x rangle - langle e x rangle \nmathrmst quad  x - z = 0 quad 0 leq z_i leq C quad forall i \n x in x langle b x rangle = 0\nendaligned","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"This reformulation separates the equality constraint from the box constraints, enabling efficient distributed solving using bipartite ADMM.","category":"page"},{"location":"S3_examples/DualSVM/#Solver-References","page":"Dual SVM","title":"Solver References","text":"","category":"section"},{"location":"S3_examples/DualSVM/#[JuMP](https://github.com/jump-dev/JuMP.jl)-Solvers","page":"Dual SVM","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"SCS: Splitting Conic Solver\nCOSMO.jl: Conic Operator Splitting Method  \nClarabel.jl: Interior Point Conic Solver\nMadNLP.jl: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/DualSVM/#Implementation-Examples","page":"Dual SVM","title":"Implementation Examples","text":"","category":"section"},{"location":"S3_examples/DualSVM/#JuMP-Implementation","page":"Dual SVM","title":"JuMP Implementation","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Here's how to implement the Dual SVM problem using JuMP:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"function solveDualSVMByJuMP(Q::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, C::Float64, solver_optimizer=SCS.Optimizer; warmup=false)\n\n    n = length(b)\n\n    # Create JuMP model with specified optimizer\n    model = Model(solver_optimizer)\n    set_silent(model)\n    \n    # Define optimization variable\n    @variable(model, x[1:n])\n    \n    # Define objective: 0.5 * <Qx, x> - <e, x>\n    @objective(model, Min, 0.5 * x' * Q * x - sum(x))\n    \n    # Define constraints: <b, x> = 0, 0 <= x <= C\n    @constraint(model, dot(b, x) == 0)\n    @constraint(model, x .>= 0)\n    @constraint(model, x .<= C)\n    \n    # Solve the problem and get solver time directly from JuMP\n    optimize!(model)\n    solver_time = solve_time(model)\n    \n    status = termination_status(model)\n    optimal_value = objective_value(model)\n\n    return optimal_value, solver_time\nend","category":"page"},{"location":"S3_examples/DualSVM/#Multiblock-Problem-Implementation","page":"Dual SVM","title":"Multiblock Problem Implementation","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Here's how to formulate the same problem as a multiblock problem using PDMO:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"function generateDualSVM(Q::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, C::Float64)\n    \n    numberVars = length(b)\n    @assert(numberVars == size(Q,1) == size(Q, 2), \"DualSVM: input dimension mismatch. \")\n\n    mbp = MultiblockProblem() \n\n    # x block\n    block_x = BlockVariable() \n    block_x.f = QuadraticFunction(0.5 * Q, -ones(numberVars), 0.0)\n    block_x.g = IndicatorHyperplane(b, 0.0)\n    block_x.val = zeros(numberVars) # initial point\n    xID = addBlockVariable!(mbp, block_x)\n\n    # z block\n    block_z = BlockVariable() \n    block_z.g = IndicatorBox(zeros(numberVars), ones(numberVars) * C)\n    block_z.val = zeros(numberVars) # initial point\n    zID = addBlockVariable!(mbp, block_z)\n\n    # constraint: x - z = 0 \n    constr = BlockConstraint() \n    addBlockMappingToConstraint!(constr, xID, LinearMappingIdentity(1.0))\n    addBlockMappingToConstraint!(constr, zID, LinearMappingIdentity(-1.0))\n    constr.rhs = spzeros(numberVars)\n    addBlockConstraint!(mbp, constr)\n    \n    return mbp \nend","category":"page"},{"location":"S3_examples/DualSVM/#Running-ADMM-with-Different-Parameters","page":"Dual SVM","title":"Running ADMM with Different Parameters","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"After generating the multiblock problem, you can solve it using various ADMM configurations:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"# ADMM with RB Adapter\nparam = ADMMParam(\n    adapter = RBAdapter(testRatio=10.0, adapterRatio=2.0),\n    presTolL2 = Inf,\n    dresTolL2 = Inf,\n    presTolLInf = 1e-4,\n    dresTolLInf = 1e-4\n)\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S3_examples/DualSVM/#Benchmark-Methodology","page":"Dual SVM","title":"Benchmark Methodology","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"The benchmark compares multiple solution approaches:","category":"page"},{"location":"S3_examples/DualSVM/#JuMP-Solvers","page":"Dual SVM","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"SCS: Splitting Conic Solver\nCOSMO: Conic Operator Splitting Method  \nClarabel: Interior Point Conic Solver\nMadNLP: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/DualSVM/#ADMM-Variants","page":"Dual SVM","title":"ADMM Variants","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Original ADMM: Basic consensus ADMM with no acceleration\nAnderson Accelerator: History-based acceleration method\nAuto-Halpern Accelerator: Adaptive step-size acceleration\nRB Adapter: Residual Balancing for automatic parameter tuning\nSRA Adapter: Spectral Residual Adaptation\nLinearized Solvers: Adaptive and doubly linearized variants","category":"page"},{"location":"S3_examples/DualSVM/#Problem-Scales","page":"Dual SVM","title":"Problem Scales","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Three different problem sizes are tested:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Small: n = 500 (number of variables)\nMedium: n = 1000  \nLarge: n = 4000","category":"page"},{"location":"S3_examples/DualSVM/#Performance-Results","page":"Dual SVM","title":"Performance Results","text":"","category":"section"},{"location":"S3_examples/DualSVM/#Small-Scale-(n-500)","page":"Dual SVM","title":"Small Scale (n = 500)","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Solver Time (s) Objective Status\nCOSMO 0.0407 -2.0304 OPTIMAL\nSCS 0.0975 -2.0304 OPTIMAL\nClarabel 0.1939 -2.0304 OPTIMAL\nIpopt 0.2473 -2.0305 LOCALLY_SOLVED\nMadNLP 8.9777 -2.0305 LOCALLY_SOLVED","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Method Time (s) Speedup Iterations Status\nDoubly Linearized (baseline) 1.35 6.67x 879 OPTIMAL\nAdaptive Linearized (γ=1.0, r=1000) 1.45 6.20x 2753 OPTIMAL\nAdaptive Linearized Simple (γ=1.0, r=1000) 1.58 5.68x 2625 OPTIMAL\nAdaptive Linearized (γ=2.0, r=1000) 1.60 5.63x 3030 OPTIMAL\nAdaptive Linearized (γ=0.5, r=1000) 1.78 5.03x 2756 OPTIMAL","category":"page"},{"location":"S3_examples/DualSVM/#Medium-Scale-(n-1000)","page":"Dual SVM","title":"Medium Scale (n = 1000)","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Solver Time (s) Objective Status\nSCS 0.2463 -2.1057 OPTIMAL\nIpopt 0.5411 -2.1057 LOCALLY_SOLVED\nCOSMO 0.6065 -2.1057 OPTIMAL\nClarabel 1.5996 -2.1057 OPTIMAL\nMadNLP 3.8568 -2.1057 LOCALLY_SOLVED","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Method Time (s) Speedup Iterations Status\nDoubly Linearized (baseline) 5.86 0.66x 1357 OPTIMAL\nOriginal ADMM + SRA Adapter 15.76 0.24x 61 OPTIMAL\nOriginal ADMM + SRA + Halpern 15.84 0.24x 61 OPTIMAL\nAdaptive Linearized (γ=0.5, r=1000) 17.95 0.21x 9568 OPTIMAL\nAdaptive Linearized Simple (γ=1.0, r=1000) 18.38 0.21x 10030 OPTIMAL","category":"page"},{"location":"S3_examples/DualSVM/#Large-Scale-(n-4000)","page":"Dual SVM","title":"Large Scale (n = 4000)","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Solver Time (s) Objective Status\nSCS 12.1316 -2.2632 OPTIMAL\nCOSMO 38.3884 -2.2632 OPTIMAL\nClarabel 156.3004 -2.2632 OPTIMAL\nMadNLP 258.7855 -2.2632 LOCALLY_SOLVED\nIpopt 306.6743 -2.2633 LOCALLY_SOLVED","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Method Time (s) Speedup Iterations Status\nDoubly Linearized (baseline) 285.60 1.07x 3348 OPTIMAL\nOriginal ADMM + SRA Adapter 1034.30 0.30x 69 OPTIMAL\nOriginal ADMM + SRA + Halpern 1050.25 0.29x 69 OPTIMAL\nAdaptive Linearized Simple (γ=1.0, r=1000) 3600.01 0.09x 98037 TIME_LIMIT\nAdaptive Linearized (γ=2.0, r=1000) 3600.01 0.09x 96944 TIME_LIMIT","category":"page"},{"location":"S3_examples/DualSVM/#Multi-Scale-Performance-Summary","page":"Dual SVM","title":"Multi-Scale Performance Summary","text":"","category":"section"},{"location":"S3_examples/DualSVM/","page":"Dual SVM","title":"Dual SVM","text":"Scale JuMP Reference Best ADMM Method ADMM Time Speedup Status\nSmall (n=500) MadNLP: 8.98s Doubly Linearized (baseline) 1.35s 6.67x OPTIMAL\nMedium (n=1000) SCS: 0.25s Doubly Linearized (baseline) 5.86s 0.66x OPTIMAL\nLarge (n=4000) SCS: 12.13s Doubly Linearized (baseline) 285.60s 1.07x OPTIMAL","category":"page"},{"location":"S3_examples/FusedLasso/#Fused-Lasso-Benchmark-Results","page":"Fused Lasso","title":"Fused Lasso Benchmark Results","text":"","category":"section"},{"location":"S3_examples/FusedLasso/#Problem-Formulation","page":"Fused Lasso","title":"Problem Formulation","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"The Fused Lasso problem combines a quadratic data fidelity term with an L1 penalty on the differences between adjacent variables:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"min_x quad frac12Ax - b^2 + lambdaDx_1","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"where:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"A is an m × n matrix\nb is an m-dimensional vector  \nx is the n-dimensional optimization variable\nλ is the regularization parameter\nD is the difference matrix:\nD = [-1  1  0 ...  0  0\n      0 -1  1 ...  0  0\n      ...\n      0  0  0 ... -1  1]","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"For ADMM decomposition, this is reformulated as a two-block problem:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"beginaligned\nmin_x z quad  frac12Ax - b^2 + lambdaz_1 \nmathrmst quad  Dx - z = 0\nendaligned","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"This reformulation enables efficient distributed solving using bipartite ADMM.","category":"page"},{"location":"S3_examples/FusedLasso/#Solver-References","page":"Fused Lasso","title":"Solver References","text":"","category":"section"},{"location":"S3_examples/FusedLasso/#[JuMP](https://github.com/jump-dev/JuMP.jl)-Solvers","page":"Fused Lasso","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"SCS: Splitting Conic Solver\nCOSMO.jl: Conic Operator Splitting Method  \nClarabel.jl: Interior Point Conic Solver\nMadNLP.jl: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/FusedLasso/#Implementation-Examples","page":"Fused Lasso","title":"Implementation Examples","text":"","category":"section"},{"location":"S3_examples/FusedLasso/#JuMP-Implementation","page":"Fused Lasso","title":"JuMP Implementation","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Here's how to implement the Fused Lasso problem using JuMP with the epigraph formulation:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"function solveFusedLassoByJuMP(A::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, D::SparseMatrixCSC{Float64, Int64}, lambda::Float64, solver_optimizer=SCS.Optimizer; warmup=false)\n\n    m, n = size(A)\n\n    # Create JuMP model with specified optimizer\n    model = Model(solver_optimizer)\n    set_silent(model)\n    \n    # Define optimization variable\n    @variable(model, x[1:n])\n    \n    # Define auxiliary variables for L1 norm ||Dx||_1\n    # We use the epigraph formulation: ||Dx||_1 <= sum(t), -t <= Dx <= t\n    d_size = size(D, 1)\n    @variable(model, t[1:d_size] >= 0)\n    \n    # Define objective: (1/2) ||Ax - b||^2 + lambda * sum(t)\n    residual = A * x - b\n    @objective(model, Min, 0.5 * sum(residual[i]^2 for i in 1:length(residual)) + lambda * sum(t))\n    \n    # Define constraints for L1 norm: -t <= Dx <= t (split into two constraints)\n    Dx = D * x\n    @constraint(model, Dx .<= t)\n    @constraint(model, Dx .>= -t)\n    \n    # Solve the problem and get solver time directly from JuMP\n    optimize!(model)\n    solver_time = solve_time(model)\n    \n    status = termination_status(model)\n    optimal_value = objective_value(model)\n\n    return optimal_value, solver_time\nend","category":"page"},{"location":"S3_examples/FusedLasso/#Multiblock-Problem-Implementation","page":"Fused Lasso","title":"Multiblock Problem Implementation","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Here's how to formulate the same problem as a multiblock problem using PDMO:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"function generateFusedLasso(A::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, lambda::Float64)\n    mbp = MultiblockProblem() \n    \n    numberRows, numberCols = size(A)\n    @assert(numberRows == length(b), \"FusedLasso: Dimension mismatch. \")\n\n    # x block\n    block_x = BlockVariable() \n    # block_x.f = FrobeniusNormSquare(Matrix(A), b, numberCols, 1, 0.5)\n    block_x.f = QuadraticFunction(0.5 * A' * A, -1.0 * A' * b, 0.5 * dot(b, b))\n    block_x.val = zeros(numberCols)\n    xID = addBlockVariable!(mbp, block_x)\n\n    # z block \n    block_z = BlockVariable() \n    block_z.g = ElementwiseL1Norm(lambda)\n    block_z.val = zeros(numberCols-1)\n    zID = addBlockVariable!(mbp, block_z)\n\n    # constraint \n    constr = BlockConstraint() \n    D = spdiagm(0 => -ones(numberCols - 1), 1 => ones(numberCols - 1))\n    D = D[1:end-1, :]\n    addBlockMappingToConstraint!(constr, xID, LinearMappingMatrix(D))\n    addBlockMappingToConstraint!(constr, zID, LinearMappingIdentity(-1.0))\n    constr.rhs = zeros(numberCols-1)\n    addBlockConstraint!(mbp, constr)\n\n    return mbp\nend","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"After generating the multiblock problem, you can solve it using various ADMM configurations:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"# ADMM with RB Adapter\nparam = ADMMParam(\n    adapter = RBAdapter(testRatio=10.0, adapterRatio=2.0),\n    presTolL2 = Inf,\n    dresTolL2 = Inf,\n    presTolLInf = 1e-4,\n    dresTolLInf = 1e-4\n)\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S3_examples/FusedLasso/#Benchmark-Methodology","page":"Fused Lasso","title":"Benchmark Methodology","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"The benchmark compares multiple solution approaches:","category":"page"},{"location":"S3_examples/FusedLasso/#JuMP-Solvers","page":"Fused Lasso","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"SCS: Splitting Conic Solver\nCOSMO: Conic Operator Splitting Method  \nClarabel: Interior Point Conic Solver\nMadNLP: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/FusedLasso/#ADMM-Variants","page":"Fused Lasso","title":"ADMM Variants","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Original ADMM: Basic consensus ADMM with no acceleration\nAnderson Accelerator: History-based acceleration method\nAuto-Halpern Accelerator: Adaptive step-size acceleration\nRB Adapter: Residual Balancing for automatic parameter tuning\nSRA Adapter: Spectral Residual Adaptation\nLinearized Solvers: Adaptive and doubly linearized variants","category":"page"},{"location":"S3_examples/FusedLasso/#Problem-Scales","page":"Fused Lasso","title":"Problem Scales","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Three different problem sizes are tested:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Small: 500 × 250 (A matrix dimensions)\nMedium: 1000 × 500  \nLarge: 4000 × 2000","category":"page"},{"location":"S3_examples/FusedLasso/#Performance-Results","page":"Fused Lasso","title":"Performance Results","text":"","category":"section"},{"location":"S3_examples/FusedLasso/#Small-Scale-(500-250)","page":"Fused Lasso","title":"Small Scale (500 × 250)","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Solver Time (s) Objective Status\nSCS 0.0151 205.4149 OPTIMAL\nCOSMO 0.0272 205.4147 OPTIMAL\nClarabel 0.0265 205.4148 OPTIMAL\nIpopt 0.1369 205.4148 LOCALLY_SOLVED\nMadNLP 7.8851 205.4148 LOCALLY_SOLVED","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + RB + Halpern 0.08 96.62x 856 OPTIMAL\nOriginal ADMM + RB Adapter 0.10 81.72x 454 OPTIMAL\nOriginal ADMM + SRA + Halpern 0.11 69.80x 63 OPTIMAL\nOriginal ADMM + SRA Adapter 0.15 52.75x 63 OPTIMAL\nOriginal ADMM + Anderson only 0.23 34.21x 159 OPTIMAL","category":"page"},{"location":"S3_examples/FusedLasso/#Medium-Scale-(1000-500)","page":"Fused Lasso","title":"Medium Scale (1000 × 500)","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Solver Time (s) Objective Status\nSCS 0.0654 394.9359 OPTIMAL\nIpopt 0.1214 394.9358 LOCALLY_SOLVED\nCOSMO 0.1286 394.9358 OPTIMAL\nClarabel 0.1522 394.9358 OPTIMAL\nMadNLP 0.4297 394.9358 LOCALLY_SOLVED","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + Anderson only 0.13 3.23x 229 OPTIMAL\nOriginal ADMM (baseline) 0.13 3.18x 880 OPTIMAL\nOriginal ADMM + Halpern only 0.28 1.54x 1707 OPTIMAL\nOriginal ADMM + RB Adapter 0.45 0.96x 867 OPTIMAL\nOriginal ADMM + RB + Halpern 0.60 0.72x 1681 OPTIMAL","category":"page"},{"location":"S3_examples/FusedLasso/#Large-Scale-(4000-2000)","page":"Fused Lasso","title":"Large Scale (4000 × 2000)","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Solver Time (s) Objective Status\nSCS 2.3063 1346.478 OPTIMAL\nIpopt 3.0954 1346.480 LOCALLY_SOLVED\nCOSMO 4.9331 1346.480 OPTIMAL\nClarabel 10.3667 1346.480 OPTIMAL\nMadNLP 47.4689 1346.480 LOCALLY_SOLVED","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + Anderson only 7.32 6.49x 474 OPTIMAL\nOriginal ADMM (baseline) 8.21 5.78x 1949 OPTIMAL\nOriginal ADMM + Halpern only 14.97 3.17x 3839 OPTIMAL\nOriginal ADMM + RB Adapter 21.57 2.20x 968 OPTIMAL\nOriginal ADMM + RB + Halpern 25.05 1.89x 1873 OPTIMAL","category":"page"},{"location":"S3_examples/FusedLasso/#Multi-Scale-Performance-Summary","page":"Fused Lasso","title":"Multi-Scale Performance Summary","text":"","category":"section"},{"location":"S3_examples/FusedLasso/","page":"Fused Lasso","title":"Fused Lasso","text":"Scale JuMP Reference Best ADMM Method ADMM Time Speedup Status\nSmall (500×250) MadNLP: 7.89s Original ADMM + RB + Halpern 0.08s 96.62x OPTIMAL\nMedium (1000×500) MadNLP: 0.43s Original ADMM + Anderson only 0.13s 3.23x OPTIMAL\nLarge (4000×2000) MadNLP: 47.47s Original ADMM + Anderson only 7.32s 6.49x OPTIMAL","category":"page"},{"location":"S3_examples/DualLasso/#Dual-Lasso-Benchmark-Results","page":"Dual Lasso","title":"Dual Lasso Benchmark Results","text":"","category":"section"},{"location":"S3_examples/DualLasso/#Problem-Formulation","page":"Dual Lasso","title":"Problem Formulation","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"The Dual Lasso problem is a quadratic programming problem with infinity norm constraints:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"beginaligned\nmin_x quad  frac14x^2 - b^top x \nmathrmst quad   Ax_infty leq lambda\nendaligned","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"where:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"A is an m × n matrix\nb is an n-dimensional vector\nx is the n-dimensional optimization variable  \nλ is the regularization parameter","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"For ADMM decomposition, this is reformulated as a two-block problem:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"beginaligned\nmin_x z quad  frac14x^2 - b^top x \nmathrmst quad   Ax - z = 0 z_infty leq lambda\nendaligned","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"This reformulation enables efficient distributed solving using bipartite ADMM.","category":"page"},{"location":"S3_examples/DualLasso/#Implementation-Examples","page":"Dual Lasso","title":"Implementation Examples","text":"","category":"section"},{"location":"S3_examples/DualLasso/#JuMP-Implementation","page":"Dual Lasso","title":"JuMP Implementation","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Here's how to implement the Dual Lasso problem using JuMP:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"using JuMP, SCS\n\nfunction solveDualLassoByJuMP(A::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, lambda::Float64, solver_optimizer=SCS.Optimizer; warmup=false)\n\n    m, n = size(A)\n\n    # Create JuMP model with specified optimizer\n    model = Model(solver_optimizer)\n    set_silent(model)\n    \n    # Define optimization variable\n    @variable(model, x[1:n])\n    \n    # Define objective: (1/4) ||x||^2 - b'x\n    @objective(model, Min, 0.25 * sum(x[i]^2 for i in 1:n) - dot(b, x))\n    \n    # Define constraint: ||Ax||_{inf} <= lambda\n    # This is equivalent to: -lambda <= (Ax)_i <= lambda for all i\n    Ax = A * x\n    @constraint(model, -lambda .<= Ax .<= lambda)\n    \n    # Solve the problem and get solver time directly from JuMP\n    optimize!(model)\n    solver_time = solve_time(model)\n    \n    status = termination_status(model)\n    optimal_value = objective_value(model)\n    optimal_x = value.(x)\n\n    return optimal_value, solver_time\nend","category":"page"},{"location":"S3_examples/DualLasso/#Multiblock-Problem-Implementation","page":"Dual Lasso","title":"Multiblock Problem Implementation","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Here's how to formulate the same problem as a multiblock problem for ADMM:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"using PDMO\n\nfunction generateDualLasso(A::SparseMatrixCSC{Float64, Int64}, b::Vector{Float64}, lambda::Float64)\n    mbp = MultiblockProblem() \n    \n    numberRows, numberCols = size(A)\n    @assert(numberCols == length(b), \"DualLasso: Dimension mismatch. \")\n\n    # x block\n    block_x = BlockVariable() \n    block_x.f = QuadraticFunction(0.25 * spdiagm(0 => ones(numberCols)), -b, 0.0)\n    block_x.val = zeros(numberCols)\n    xID = addBlockVariable!(mbp, block_x)\n\n    # z block \n    block_z = BlockVariable() \n    block_z.g = IndicatorBox(-lambda * ones(numberRows), ones(numberRows) * lambda)\n    block_z.val = zeros(numberRows)\n    zID = addBlockVariable!(mbp, block_z)\n\n    # constraint \n    constr = BlockConstraint() \n    addBlockMappingToConstraint!(constr, xID, LinearMappingMatrix(A))\n    addBlockMappingToConstraint!(constr, zID, LinearMappingIdentity(-1.0))\n    constr.rhs = zeros(numberRows)\n    addBlockConstraint!(mbp, constr)\n\n    return mbp\nend ","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"After generating the multiblock problem, you can solve it using various ADMM configurations:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"# ADMM with RB Adapter\nparam = ADMMParam(\n    adapter = RBAdapter(testRatio=10.0, adapterRatio=2.0),\n    presTolL2 = Inf,\n    dresTolL2 = Inf,\n    presTolLInf = 1e-4,\n    dresTolLInf = 1e-4\n)\nresult = runBipartiteADMM(mbp, param)","category":"page"},{"location":"S3_examples/DualLasso/#Benchmark-Methodology","page":"Dual Lasso","title":"Benchmark Methodology","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"The benchmark compares multiple solution approaches:","category":"page"},{"location":"S3_examples/DualLasso/#[JuMP](https://github.com/jump-dev/JuMP.jl)-Solvers","page":"Dual Lasso","title":"JuMP Solvers","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"SCS: Splitting Conic Solver\nCOSMO.jl: Conic Operator Splitting Method  \nClarabel.jl: Interior Point Conic Solver\nMadNLP.JL: Nonlinear Programming Solver\nIpopt: Interior Point Optimizer","category":"page"},{"location":"S3_examples/DualLasso/#ADMM-Variants","page":"Dual Lasso","title":"ADMM Variants","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Original ADMM: Baseline implementation\nAccelerated Methods: Anderson and Auto-Halpern acceleration\nAdaptive Methods: RB and SRA adapters\nLinearized Methods: Adaptive and doubly linearized solvers","category":"page"},{"location":"S3_examples/DualLasso/#Problem-Scales","page":"Dual Lasso","title":"Problem Scales","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Small Scale: 100 × 200 (λ = 2.0)\nMedium Scale: 2000 × 3000 (λ = 2.0)  \nLarge Scale: 4000 × 8000 (λ = 2.0)","category":"page"},{"location":"S3_examples/DualLasso/#Performance-Results","page":"Dual Lasso","title":"Performance Results","text":"","category":"section"},{"location":"S3_examples/DualLasso/#Small-Scale-(100-200)","page":"Dual Lasso","title":"Small Scale (100 × 200)","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Solver Time (s) Status Objective\nMadNLP 7.66 LOCALLY_SOLVED -118.780846\nIpopt 0.12 LOCALLY_SOLVED -118.780846\nClarabel 0.08 OPTIMAL -118.780845\nSCS 0.01 OPTIMAL -118.780846\nCOSMO 0.004 OPTIMAL -118.780846","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + RB + Halpern 0.02 458.87x 77 OPTIMAL\nOriginal ADMM + SRA + Halpern 0.02 314.57x 61 OPTIMAL\nOriginal ADMM + SRA Adapter 0.03 238.37x 61 OPTIMAL\nOriginal ADMM + RB Adapter 0.07 104.77x 77 OPTIMAL\nOriginal ADMM + Halpern only 1.91 4.01x 26909 OPTIMAL","category":"page"},{"location":"S3_examples/DualLasso/#Medium-Scale-(2000-3000)","page":"Dual Lasso","title":"Medium Scale (2000 × 3000)","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Solver Time (s) Status Objective\nClarabel 252.44 OPTIMAL -1114.120645\nSCS 31.25 OPTIMAL -1114.120651\nMadNLP 30.26 LOCALLY_SOLVED -1114.120644\nIpopt 18.20 LOCALLY_SOLVED -1114.120647\nCOSMO 16.89 OPTIMAL -1114.120648","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + RB Adapter 15.24 16.57x 158 OPTIMAL\nOriginal ADMM + SRA Adapter 15.41 16.38x 169 OPTIMAL\nOriginal ADMM + RB + Halpern 17.04 14.82x 248 OPTIMAL\nOriginal ADMM + SRA + Halpern 18.17 13.90x 283 OPTIMAL\nOriginal ADMM + Anderson only 356.66 0.71x 9061 OPTIMAL","category":"page"},{"location":"S3_examples/DualLasso/#Large-Scale-(4000-8000)","page":"Dual Lasso","title":"Large Scale (4000 × 8000)","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"JuMP Solver Performance:","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Solver Time (s) Status Objective\nClarabel 2387.48 OPTIMAL -4156.277839\nSCS 288.69 OPTIMAL -4156.277722\nMadNLP 228.98 LOCALLY_SOLVED -4156.277834\nIpopt 211.54 LOCALLY_SOLVED -4156.277834\nCOSMO 158.64 OPTIMAL -4156.277843","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"ADMM Performance (Top 5):","category":"page"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Method Time (s) Speedup Iterations Status\nOriginal ADMM + SRA Adapter 103.91 22.98x 350 OPTIMAL\nOriginal ADMM + SRA + Halpern 140.49 16.99x 644 OPTIMAL\nOriginal ADMM + RB Adapter 147.68 16.17x 347 OPTIMAL\nOriginal ADMM + RB + Halpern 186.31 12.81x 638 OPTIMAL\nAdaptive Linearized Simple (γ=1.0, r=1000) 3600.03 0.66x 31305 TIME_LIMIT","category":"page"},{"location":"S3_examples/DualLasso/#Multi-Scale-Performance-Summary","page":"Dual Lasso","title":"Multi-Scale Performance Summary","text":"","category":"section"},{"location":"S3_examples/DualLasso/","page":"Dual Lasso","title":"Dual Lasso","text":"Scale JuMP Reference Best ADMM Method ADMM Time Speedup Status\nSmall (100×200) MadNLP: 7.66s Original ADMM + RB + Halpern 0.02s 458.87x OPTIMAL\nMedium (2000×3000) Clarabel: 252.44s Original ADMM + RB Adapter 15.24s 16.57x OPTIMAL\nLarge (4000×8000) Clarabel: 2387.48s Original ADMM + SRA Adapter 103.91s 22.98x OPTIMAL","category":"page"},{"location":"S2_algorithms/AdaPDM/#Adaptive-Primal-Dual-Methods-(AdaPDM)","page":"AdaPDM","title":"Adaptive Primal-Dual Methods (AdaPDM)","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/#Introduction-and-Solution-Process-Overview","page":"AdaPDM","title":"Introduction and Solution Process Overview","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Adaptive Primal-Dual Methods (AdaPDM) are optimization algorithms designed to solve composite optimization problems with specific structural constraints. Unlike ADMM which requires bipartization for multiblock problems, AdaPDM methods work directly on problems that naturally satisfy a composite structure.","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"The AdaPDM framework solves problems of the form:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"beginaligned\nmin_mathbfx quad   sum_j=1^n-1 left( f_j(x_j) + g_j(x_j) right) + g_n(x_n) \ntextst quad  mathbfA_11x_1 + mathbfA_2x_2 + cdots + mathbfA_1n-1x_n-1 - x_n+1 = 0\nendaligned","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"or equivalently, ","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"beginaligned\nmin_mathbfx quad   sum_j=1^n-1 left( f_j(x_j) + g_j(x_j) right) + g_n(mathbfA_11x_1 + mathbfA_12x_2 + cdots + mathbfA_1n-1x_n-1)\nendaligned","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"The algorithm alternates between dual and primal updates:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"beginalign\n   y^k+1 = textprox_sigma g_n^*(y^k + sigma Abarx^k) notag \n   x_j^k+1 = textprox_gamma g_j(x_j^k - gamma(nabla f_j(x_j^k) + mathbfA_1j^top y^k+1)) quad j=1ldotsn-1 notag \nendalign","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"where barx^k includes extrapolation terms, and sigma and gamma are adaptive step sizes.","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"PDMO.jl implements a comprehensive AdaPDM framework with automated three-stage process:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Problem Validation: Verify the MultiblockProblem conforms to the required composite structure\nAlgorithm Selection: Initialize the selected algorithm with user-specified parameters\nIterative Solution: Apply primal-dual updates until convergence","category":"page"},{"location":"S2_algorithms/AdaPDM/#Composite-Problem-Structure-and-Validation","page":"AdaPDM","title":"Composite Problem Structure and Validation","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"AdaPDM methods require problems to satisfy a specific composite structure:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Validation Criteria:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Single Constraint: Exactly one constraint of the form sum_i=1^n A_i x_i - x_n+1 = 0\nZero Right-Hand Side: The constraint must have zero right-hand side\nProximal-Only Block: One block must have f_n+1 = 0 (proximal-only) with mapping coefficient -10\nFunction Properties: f_i must be smooth convex functions, g_i must be proximal-friendly","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Automatic Processing:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Block reordering to ensure required (x_1 ldots x_p x_p+1) structure\nOperator norm estimation when not provided","category":"page"},{"location":"S2_algorithms/AdaPDM/#AdaPDM-Algorithm-Variants","page":"AdaPDM","title":"AdaPDM Algorithm Variants","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"PDMO.jl implements four distinct AdaPDM variants with different step size strategies. Unlike in ADMM where a specific variant is selected through solver field in ADMMParameter, we directly pass different algorithmic parameters to specify a particular variant. ","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Algorithm Parameter Reference\nCondat-Vũ CondatVuParam [1], [2]\nAdaPDM AdaPDMParam Algorithm 3.1 of [3]\nAdaPDM+ AdaPDMPlusParam Algorithm 3.2 of [3]\nMalitsky-Pock MalitskyPockParam [4]","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Please refer to original papers on how to tune each method. ","category":"page"},{"location":"S2_algorithms/AdaPDM/#Condat-Vũ-(CondatVuParam)","page":"AdaPDM","title":"Condat-Vũ (CondatVuParam)","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Classical primal-dual method with fixed step sizes:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"param = CondatVuParam(mbp;\n    alphaProvided = Inf,                     # Primal step size (auto-computed if Inf)\n    betaProvided = Inf,                      # Dual step size (auto-computed if Inf)\n    opNormEstimateProvided = Inf,            # Operator norm estimate\n    LipschitzConstantEstimateProvided = Inf, # Lipschitz constant estimate\n    presTolL2 = 1e-4,                        # Primal residual tolerance in L2 norm\n    dresTolL2 = 1e-4,                        # Dual residual tolerance in L2 norm\n    presTolLInf = 1e-6,                      # Primal residual tolerance in L∞ norm\n    dresTolLInf = 1e-6,                      # Dual residual tolerance in L∞ norm\n    lineSearchMaxIter = 1000,                # Maximum iterations for line search\n    maxIter = 10000,                         # Maximum iterations\n    logInterval = 1000,                      # Logging interval\n    timeLimit = 3600.0                       # Time limit in seconds\n)\nresult = runAdaPDM(mbp, param)","category":"page"},{"location":"S2_algorithms/AdaPDM/#AdaPDM-(AdaPDMParam)","page":"AdaPDM","title":"AdaPDM (AdaPDMParam)","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Basic adaptive primal-dual method with automatic step size selection:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"param = AdaPDMParam(mbp;\n    t = 1.0,                        # Primal/dual step size ratio\n    stepSizeEpsilon = 1e-6,         # Step size parameter epsilon  \n    stepSizeNu = 1.2,               # Step size parameter nu\n    opNormEstimateProvided = Inf,   # Operator norm estimate (auto-computed if Inf)\n    presTolL2 = 1e-4,               # Primal residual tolerance in L2 norm\n    dresTolL2 = 1e-4,               # Dual residual tolerance in L2 norm\n    presTolLInf = 1e-6,             # Primal residual tolerance in L∞ norm\n    dresTolLInf = 1e-6,             # Dual residual tolerance in L∞ norm\n    maxIter = 10000,                # Maximum iterations\n    logInterval = 1000,             # Logging interval\n    timeLimit = 3600.0              # Time limit in seconds\n)\nresult = runAdaPDM(mbp, param)","category":"page"},{"location":"S2_algorithms/AdaPDM/#AdaPDM-(AdaPDMPlusParam)","page":"AdaPDM","title":"AdaPDM+ (AdaPDMPlusParam)","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Enhanced version with line search and adaptive operator norm estimation:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"param = AdaPDMPlusParam(mbp;\n    t = 1.0,                              # Primal/dual step size ratio\n    stepSizeEpsilon = 1e-6,               # Step size parameter epsilon\n    stepSizeNu = 1.2,                     # Step size parameter nu\n    opNormEstimateProvided = Inf,         # Operator norm estimate (auto-computed if Inf)\n    backtrackingFactor = 2.0,             # Line search backtracking factor\n    normEstimateShrinkingFactor = 0.95,   # Operator norm shrinking factor\n    presTolL2 = 1e-4,                     # Primal residual tolerance in L2 norm\n    dresTolL2 = 1e-4,                     # Dual residual tolerance in L2 norm\n    presTolLInf = 1e-6,                   # Primal residual tolerance in L∞ norm\n    dresTolLInf = 1e-6,                   # Dual residual tolerance in L∞ norm\n    lineSearchMaxIter = 1000,             # Maximum iterations for line search\n    maxIter = 10000,                      # Maximum iterations\n    logInterval = 1000,                   # Logging interval\n    timeLimit = 3600.0                    # Time limit in seconds\n)\nresult = runAdaPDM(mbp, param)","category":"page"},{"location":"S2_algorithms/AdaPDM/#Malitsky-Pock-(MalitskyPockParam)","page":"AdaPDM","title":"Malitsky-Pock (MalitskyPockParam)","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Specialized method with backtracking and theoretical convergence guarantees:","category":"page"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"param = MalitskyPockParam(mbp;\n    initialTheta = 1.0,                # Initial primal step size ratio\n    initialSigma = 1.0,                # Initial dual step size\n    backtrackDescentRatio = 0.95,      # Backtrack descent ratio in (0,1)\n    t = 1.0,                           # Ratio for primal dual step sizes\n    mu = 0.8,                          # Backtrack parameter in (0,1)\n    presTolL2 = 1e-4,                  # Primal residual tolerance in L2 norm\n    dresTolL2 = 1e-4,                  # Dual residual tolerance in L2 norm\n    presTolLInf = 1e-6,                # Primal residual tolerance in L∞ norm\n    dresTolLInf = 1e-6,                # Dual residual tolerance in L∞ norm\n    lineSearchMaxIter = 1000,          # Maximum iterations for line search\n    maxIter = 10000,                   # Maximum iterations\n    logInterval = 1000,                # Logging interval\n    timeLimit = 3600.0                 # Time limit in seconds\n)\nresult = runAdaPDM(mbp, param)","category":"page"},{"location":"S2_algorithms/AdaPDM/#References","page":"AdaPDM","title":"References","text":"","category":"section"},{"location":"S2_algorithms/AdaPDM/","page":"AdaPDM","title":"AdaPDM","text":"Condat, L. (2013). A primal–dual splitting method for convex optimization involving Lipschitzian, proximable and linear composite terms. Journal of Optimization Theory and Applications, 158(2), 460-479.\nVũ, B. C. (2013). A splitting algorithm for dual monotone inclusions involving cocoercive operators. Advances in Computational Mathematics, 38(3), 667-681.\nLatafat, P., Themelis, A., Stella, L., & Patrinos, P. (2024). Adaptive proximal algorithms for convex optimization under local Lipschitz continuity of the gradient. Mathematical Programming, 1-39.\nMalitsky, Y., & Pock, T. (2018). A first-order primal-dual algorithm with linesearch. SIAM Journal on Optimization, 28(1), 411-432.","category":"page"},{"location":"S4_api/formulations/#Formulations","page":"Formulations","title":"Formulations","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"This page documents the problem formulation components in PDMO.jl for defining optimization problems.","category":"page"},{"location":"S4_api/formulations/#Overview","page":"Formulations","title":"Overview","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"PDMO.jl provides a flexible framework for formulating multiblock optimization problems with block variables, constraints, and linear operators.","category":"page"},{"location":"S4_api/formulations/#Block-Components","page":"Formulations","title":"Block Components","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Core building blocks for multiblock problems:","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"BlockVariable - Represents a block of optimization variables\nBlockConstraint - Represents a constraint involving multiple variable blocks","category":"page"},{"location":"S4_api/formulations/#Problem-Representation","page":"Formulations","title":"Problem Representation","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Main structures for defining optimization problems:","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"MultiblockProblem - Core problem representation with multiple variable blocks\nMultiblockGraph - Graph representation of problem structure showing variable-constraint relationships","category":"page"},{"location":"S4_api/formulations/#JuMP-Integration","page":"Formulations","title":"JuMP Integration","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Integration with JuMP.jl for modeling:","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"MultiblockProblemJuMP - Interface between JuMP models and multiblock problems\nAutomatic extraction of block structure from JuMP models","category":"page"},{"location":"S4_api/formulations/#Problem-Transformation","page":"Formulations","title":"Problem Transformation","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Utilities for problem preprocessing and transformation:","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"MultiblockProblemScaling - Automatic scaling of variables and constraints\nProblem transformation utilities for improved numerical stability","category":"page"},{"location":"S4_api/formulations/#Graph-Algorithms","page":"Formulations","title":"Graph Algorithms","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Specialized algorithms for multiblock problem graphs:","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"BipartizationAlgorithms - Algorithms for converting general graphs to bipartite form\nADMMBipartiteGraph - Bipartite graph representation optimized for ADMM algorithms","category":"page"},{"location":"S4_api/formulations/#Graph-Analysis","page":"Formulations","title":"Graph Analysis","text":"","category":"section"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Tools for analyzing problem structure:","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Graph connectivity analysis\nBlock decomposition strategies\nComputational complexity estimation","category":"page"},{"location":"S4_api/formulations/","page":"Formulations","title":"Formulations","text":"Note: Detailed API documentation with function signatures and examples will be added in a future release.","category":"page"},{"location":"#PDMO.jl-**Primal-Dual-Methods-for-Optimization**","page":"Home","title":"PDMO.jl - Primal-Dual Methods for Optimization","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PDMO.jl is a powerful Julia framework for primal-dual multiblock optimization, built for rapid prototyping and high-performance computing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Solve Complex Problems: Model and solve problems with multiple variable blocks and linear coupling constriants. \nHighly Customizable: An open-source toolkit that is easy to adapt for your applications and specific algorithms.\nAccelerate Research: Benchmark your methods against classic and","category":"page"},{"location":"","page":"Home","title":"Home","text":"state-of-the-art solvers.","category":"page"},{"location":"#Problem-Formulation","page":"Home","title":"Problem Formulation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PDMO.jl presents a unified framework for formulating and solving a MultiblockProblem of the form: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\nmin_mathbfx quad  sum_j=1^n left( f_j(x_j) + g_j(x_j) right) \nmathrmst quad   mathbfA mathbfx = mathbfb\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"where we have the following problem variables and data:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginarrayccc\nntextbfBlock Variables quad  mtextbf Block Constraints quad  textbfBlock Matrix (m times n  textbflinear operators) \nmathbfx = beginbmatrix x_1  x_2  vdots  x_n endbmatrix quad  mathbfb = beginbmatrix b_1  b_2  vdots  b_m endbmatrix quad  mathbfA = beginbmatrix mathbfA_11  mathbfA_12  cdots  mathbfA_1n  mathbfA_21  mathbfA_22  cdots  mathbfA_2n  vdots  vdots  ddots  vdots  mathbfA_m1  mathbfA_m2  cdots  mathbfA_mn endbmatrix \nendarray","category":"page"},{"location":"","page":"Home","title":"Home","text":"More specifically, ","category":"page"},{"location":"","page":"Home","title":"Home","text":"For each jin 1cdotsn, a BlockVariable x_j represents a numeric array (i.e., scalar, vector, matrix, etc.), and is associated with two objective functions: \neach f_j is differentiable, and f_j(cdot) and nabla f_j(cdot) are available; \neach g_j is proximable, and g_j(cdot) and textprox_gamma g_j(cdot) are available.\nFor each i in 1cdotsm, a BlockConstraint is defined by some linear operators and a right-hand side array: \nthe linear operator mathbfA_ij is non-zero if and only if constraint i involves blocks x_j;\nthe adjoint operator of mathbfA_ij is available;\nthe right-hand side b_i can be a numeric array of any shape. ","category":"page"},{"location":"#Algorithms","page":"Home","title":"Algorithms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PDMO.jl provides various algorithms to solve problems of the above form.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Alternating Direction Method of Multipliers (ADMM)\nGraph-based bipartization methods automatically generate ADMM-ready reformulations of MultiblockProblem.\nVarious ADMM variants are available: \nOriginal ADMM \nDoubly linearized ADMM \nAdaptive linearized ADMM \nVarious algorithmic component can be selected: \nPenalty adapters, e.g., Residual Balancing, Spectral Radius Approximation\nAccelerators, e.g., Halpern (with or without restart), Filtered Anderson\nAdaptive Primal-Dual Method (AdaPDM)\nA suite of efficient and adaptive methods for problems with simpler coupling, i.e., m=1, f_n = 0, and mathbfA_1 n = -mathrmId. \n  beginaligned\n  min_mathbfx quad  sum_j=1^n-1 left( f_j(x_j) + g_j(x_j) right) + g_n(mathbfA_11x_1 + cdots + mathbfA_1n-1x_n-1)\n  endaligned\nVarious methods can be selected: \nOriginal Condat-Vu\nAdaPDM \nAdaPDM+\nMalitsky-Pock","category":"page"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"🧱 Unified Modeling: A versatile interface for structured problems.\n🔄 Automatic Decomposition: Intelligently analyzes and reformulates problems for supported algorithms.\n🧩 Extensible by Design: Easily add custom functions, constraints, and algorithms.\n📊 Modular Solvers: A rich library of classic and modern algorithms.\n⚡  Non-Convex Ready: Equipped with features to tackle non-convexity.","category":"page"},{"location":"#Roadmap-(Work-in-Progress)","page":"Home","title":"Roadmap (Work in Progress)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"🔍 Classification and detection for pathological problems\n🚀 Advanced acceleration techniques for first-order methods \n🤖 AI coding assistant for user-defined functions\n🛣️ Parallel, distributed, and GPU support.","category":"page"},{"location":"#Use-Cases","page":"Home","title":"Use Cases","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For Researchers Developing New Methods:\nA testbed for easily experimenting with your methods against existing ones \nA platform to track academic advances in first-order methods\nFor Optimization Users:\nAn open-sourced producet that is higly competitive\nEasy to use: unifying formulation, intuitive APIs, and comprehensive documentation\nModular design: minimal effort required to customize applications and algorithms","category":"page"},{"location":"#This-Documentation","page":"Home","title":"This Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Check out Getting Started for installation guide and your first optimization problem with PDMO.jl.\nLearn more about the theoretical foundations of ADMM and AdaPDM, and how to explore different algorithmic components for better performance. \nSee Examples for pre-defined templates of some classic applications and benchmark results.\nCheck out API References to implement and customize your own algorithms","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PDMO.jl is open source and welcomes contributions! Please contact info@mindopt.tech for more details.","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Currently PDMO.jl is under the MIT License.","category":"page"}]
}
